{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05. Seq2Seq 기본 구현",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAhZ_fGTwpJE"
      },
      "source": [
        "# LSTM의 `return_sequences`, `return_state` 이해하기\n",
        "* `return_sequences` : 매 타임 스텝의 출력 여부 결정 결정\n",
        "* `return_state` : 제일 마지막 스테이트 출력 여부 결정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G62k2zEw_HM"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.layers import LSTM"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pscOy-i2xIyU"
      },
      "source": [
        "sample_train = np.random.randn(1, 4, 5) # (N, L, I) : (데이터개수, 최대타임스탭, 임베딩차원)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMPyh9cUxwfY"
      },
      "source": [
        "`return_sequences=False`, `return_state=False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTEgjg2px8oC",
        "outputId": "b2040b64-1011-4ad6-fbe6-00b4f39a8307"
      },
      "source": [
        "# 제일 마지막 hidden state만 반환된다.\n",
        "last_hidden_state = LSTM(3, return_sequences=False, return_state=False)(sample_train)\n",
        "print(last_hidden_state)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[0.1270768  0.5852918  0.05390989]], shape=(1, 3), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHltiKP_yQMf"
      },
      "source": [
        "`return_sequences=False`, `return_state=True`\n",
        "\n",
        "* `hidden_states` = `last_hidden_state`\n",
        "* `last_cell_state`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHUKR15fywlG",
        "outputId": "eece0e15-bfb2-448b-c45e-0db01097eb6a"
      },
      "source": [
        "hidden_states, last_hidden_state, last_cell_state = LSTM(3, return_sequences=False, return_state=True)(sample_train)\n",
        "print(\"hidden_states : {}\".format(hidden_states))\n",
        "print(\"last_hidden_state : {}\".format(last_hidden_state))\n",
        "print(\"last_cell_state : {}\".format(last_cell_state))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden_states : [[-0.1230509  -0.12402871 -0.01906718]]\n",
            "last_hidden_state : [[-0.1230509  -0.12402871 -0.01906718]]\n",
            "last_cell_state : [[-0.18105246 -0.13825296 -0.03515929]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZVt0JiWzJb-"
      },
      "source": [
        "`return_sequences=True`, `return_state=False`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AroeYkmozxgk",
        "outputId": "a799d1d7-b772-484e-f58f-34a00a189f17"
      },
      "source": [
        "hidden_states = LSTM(3, return_sequences=True, return_state=False)(sample_train)\n",
        "print(\"hidden_states : {} / shape : {}\".format(hidden_states, hidden_states.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden_states : [[[-0.11384317 -0.04172194  0.04565322]\n",
            "  [-0.28455564 -0.43353674 -0.00277211]\n",
            "  [-0.2895847  -0.4830808  -0.32144073]\n",
            "  [-0.18519112 -0.3412207   0.03781172]]] / shape : (1, 4, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDA1BKuz0_Bn"
      },
      "source": [
        "`return_sequences=True`,`return_state=True`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUe60VrH1Oco",
        "outputId": "23601b36-18cc-4b2b-82ea-b40108ea2453"
      },
      "source": [
        "hidden_states, last_hidden_state, last_cell_state = LSTM(3, return_sequences=True, return_state=True)(sample_train)\n",
        "print(\"hidden_states : {}\".format(hidden_states))\n",
        "print(\"last_hidden_state : {}\".format(last_hidden_state))\n",
        "print(\"last_cell_state : {}\".format(last_cell_state))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hidden_states : [[[ 0.17464027  0.20474215 -0.16715199]\n",
            "  [-0.04145287 -0.03030119 -0.26777637]\n",
            "  [-0.09709232 -0.16504493 -0.19007929]\n",
            "  [-0.04109285 -0.10302802 -0.32218415]]]\n",
            "last_hidden_state : [[-0.04109285 -0.10302802 -0.32218415]]\n",
            "last_cell_state : [[-0.45237607 -0.7649007  -0.5107193 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nESWQIl11Oo7"
      },
      "source": [
        "# Seq2Seq로 챗봇 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G94VfLE_3D6_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf1b9053-92f8-4340-ca82-2cb2c61f6998"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 218 kB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 66.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FgS9Cyg3O8M"
      },
      "source": [
        "import random # 나중에 데이터 셔플링 할 예정\n",
        "import tensorflow as tf\n",
        "from konlpy.tag import Okt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNoK05fg3ct1"
      },
      "source": [
        "## 하이퍼 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKHTS9VS3sCK"
      },
      "source": [
        "num_epochs=200\n",
        "vocab_size=2000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9AZlQjG32Wn"
      },
      "source": [
        "# Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhBMlIs03_Kt"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.emb  = tf.keras.layers.Embedding(vocab_size, 64)\n",
        "\n",
        "    # 제일 마지막 state를 리턴해야 context vector가 나옴!\n",
        "    self.lstm = tf.keras.layers.LSTM(512, return_sequences=False, return_state=True)\n",
        "\n",
        "  def call(self, x, training=False):\n",
        "    # 임베딩\n",
        "    x = self.emb(x)\n",
        "\n",
        "    # Encoder에서는 context vector만 얻어내면 되기 때문에 각 time 별 state는 필요가 없다.\n",
        "    _, h, c = self.lstm(x)\n",
        "\n",
        "    # context vector return\n",
        "    return h, c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfSgMxS54BcE"
      },
      "source": [
        "# Decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saQMNwmd4Ccy"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.emb = tf.keras.layers.Embedding(vocab_size, 64)\n",
        "    self.lstm = tf.keras.layers.LSTM(512, return_sequences=True, return_state=True)\n",
        "\n",
        "    # 각 셀마다 2000개의 output을 내고, 어떤 단어가 추정 되었을지를 계산\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size, activation='softmax')\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    x, h, c = inputs # shifted, hidden_state, cell_state\n",
        "    x = self.emb(x) # 입력한 단어에 대한 임베딩 벡터\n",
        "\n",
        "    # y_ : 해당 시퀀스의 hidden_state\n",
        "    y_, h, c = self.lstm(x, initial_state=[h, c]) # initial_state : 초기화 할 hidden_state, cell_state를 지정\n",
        "\n",
        "    y = self.dense(y_)\n",
        "\n",
        "    return y, h, c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEdVpeTZ4ENi"
      },
      "source": [
        "# Seq2Seq"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZUxAvrd4LyT"
      },
      "source": [
        "class Seq2seq(tf.keras.Model):\n",
        "  \n",
        "  def __init__(self, sos, eos):\n",
        "    super(Seq2seq, self).__init__()\n",
        "    self.sos = sos # decoder에서 사용되어질 sos\n",
        "    self.eos = eos # encoder에서 사용되어질 eos\n",
        "\n",
        "    self.enc = Encoder()\n",
        "    self.dec = Decoder()\n",
        "\n",
        "  def call(self, inputs, training=False):\n",
        "    \n",
        "    if training: # 훈련에서는 Teacher Forcing 때문에 정답이 들어옴\n",
        "\n",
        "      x, y = inputs # (output_labels, shifted labels)\n",
        "      h, c = self.enc(x) # context vector가 등장\n",
        "      \n",
        "      y, _, __ = self.dec((y, h, c)) # teacher forcing. Decoder의 입력으로 Shifted Output을 넣어줌\n",
        "      \n",
        "      return y\n",
        "    else: # 테스트 할 때는 x만 들어 온다..\n",
        "      x = inputs\n",
        "      h, c = self.enc(x) # last_cell_state, last_hidden_state\n",
        "      \n",
        "      # <sos> 입력\n",
        "      # <sos> 토큰을 tensor 배열화 시켜야 함\n",
        "      y = tf.convert_to_tensor(self.sos) # 0 rank tensor로 변환\n",
        "      y = tf.reshape(y, (1, 1)) # <sos>가 (1, 1)형식으로 변환. ( 1배치, 1타임 스텝)을 의미. embedding 레이어에 넣을 예정\n",
        "\n",
        "      # 최대 입력 길이 만큼의 공간을 미리 만들어 놓자\n",
        "      seq = tf.TensorArray(tf.int32, 64) # 64개의 텐서 배열 만들어 놓기\n",
        "\n",
        "      # tensorflow의 session 환경에서 for문을 조금 더 빠르게 돌릴 수 있다!\n",
        "      for idx in tf.range(64):\n",
        "        # 제일 처음엔 <sos>, 인코더의 h, c (context vector)가 들어간다.\n",
        "        ############################################################\n",
        "        y, h, c = self.dec([y, h, c]) # 리턴 받는 y는 softmax의 결과\n",
        "        ############################################################\n",
        "        y = tf.cast(tf.argmax(y, axis=-1), dtype=tf.int32)\n",
        "\n",
        "                                  # 한 문장 들어 가서 하나의 결과. 1배치가 들어가니까 나오는 것도 1개\n",
        "        y = tf.reshape(y, (1, 1)) # (1 배치, 1단어를 의미하기 위해 reshape - 테스트 할 때는 배치를 1로 설정할 예정..)\n",
        "\n",
        "        seq = seq.write(idx, y) # 순서대로 write\n",
        "\n",
        "        if y == self.eos:\n",
        "          break\n",
        "      \n",
        "      return tf.reshape(seq.stack(), (1, 64))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWvpZtLKXEKL"
      },
      "source": [
        "# 학습, 테스트 루프 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaHb7TUjXyD0"
      },
      "source": [
        "@tf.function\n",
        "def train_step(model, inputs, labels, loss_object, optimizer, train_loss, train_accuarcy):\n",
        "  # labels는 <sos>, <eos> 를 포함한 정보\n",
        "  # output_labels : <sos>를 제외하고 <eos>를 포함해서 만든다.\n",
        "  output_labels = labels[:, 1:]\n",
        "  # shifted_lables : <sos>를 포함하고 <eos>를 제외해서 만든다.\n",
        "  shifted_labels = labels[:, :-1]\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    # inputs : x의 역할. Encoder에 들어감\n",
        "    # shifted_labels : Encoder가 예측하고, 예측해야 할 데이터\n",
        "    predictions = model([inputs, shifted_labels], training=True) # 예측을 하고\n",
        "    loss = loss_object(output_labels, predictions) # 정답이 이거였어~ 라고 이야기 하는 것\n",
        "  \n",
        "  gradients = tape.gradient(loss, model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "  \n",
        "  train_loss(loss)\n",
        "  train_accuracy(output_labels, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(model, inputs):\n",
        "  # 입력 데이터만 주고 추론은 모델이 알아서 할 수 있도록...\n",
        "  return model(inputs, training=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vpAEXCwjUUc"
      },
      "source": [
        "# 데이터셋 준비\n",
        "* http://www.aihub.or.kr"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI74X4AxjgID"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "\n",
        "dataset_file = \"chatbot_data.csv\"\n",
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtn8B48Pj0CF"
      },
      "source": [
        "with open(dataset_file, 'r') as file:\n",
        "  lines = file.readlines()\n",
        "  seq = [\" \".join(okt.morphs(line)) for line in lines]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxYPfEHzkHs_",
        "outputId": "945c4567-2d1e-4233-ab62-1434bc74a286"
      },
      "source": [
        "seq[:6]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아이스 아메리카노 하나요 \\n',\n",
              " '테이크아웃 하실 건가 요 ? \\n',\n",
              " '저 카푸치노 로 주문 할게요 \\n',\n",
              " '시럽 은 얼마나 뿌려 드릴 까요 ? \\n',\n",
              " '저 도장 다 모았는데 나중 에 써도 되나요 ? \\n',\n",
              " '네 다음 에 써도 됩니다 \\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNXC6bISkNty",
        "outputId": "6b027bd3-2874-42a7-ff24-1588d563cd24"
      },
      "source": [
        "questions = seq[::2]\n",
        "answers = [\"\\t \" + lines for lines in seq[1::2]] # \\t : <sos>\n",
        "\n",
        "print(questions[:3])\n",
        "print(answers[:3])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['아이스 아메리카노 하나요 \\n', '저 카푸치노 로 주문 할게요 \\n', '저 도장 다 모았는데 나중 에 써도 되나요 ? \\n']\n",
            "['\\t 테이크아웃 하실 건가 요 ? \\n', '\\t 시럽 은 얼마나 뿌려 드릴 까요 ? \\n', '\\t 네 다음 에 써도 됩니다 \\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYE0RwZMlJZC"
      },
      "source": [
        "# 데이터 잘라내기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dZxVwIallFd",
        "outputId": "4ce10445-b8ab-4806-c9fb-5f4ffc0e5657"
      },
      "source": [
        "num_samples = len(questions)\n",
        "print(num_samples)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9uj_CQuOlr4q",
        "outputId": "7b735278-8d90-4e40-b37e-2345c84724f7"
      },
      "source": [
        "term = list(range(num_samples))\n",
        "print(\"섞이기 전 : {}\".format(term[:10]))\n",
        "# 랜덤 시드 고정\n",
        "random.seed(0)\n",
        "random.shuffle(term)\n",
        "\n",
        "print(\"섞인 후 : {}\".format(term[:10]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "섞이기 전 : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "섞인 후 : [419, 459, 130, 431, 370, 26, 201, 56, 366, 108]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlZc0irqmBZv"
      },
      "source": [
        "* questions : 입력 데이터(inputs)\n",
        "* answers : 예측 레이블 (outputs)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP4HCL5KmcXa"
      },
      "source": [
        "train_q = [] # X_train\n",
        "train_a = [] # y_train\n",
        "\n",
        "test_q = [] # X_test\n",
        "test_a = [] # y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iSPW7pkm5Gr"
      },
      "source": [
        "test_ratio = 0.2\n",
        "test_cnt = int(len(questions) * test_ratio)\n",
        "\n",
        "train_indices = term[test_cnt: ]\n",
        "test_indices  = term[:test_cnt]\n",
        "\n",
        "for idx in train_indices:\n",
        "  train_q.append(questions[idx])\n",
        "  train_a.append(answers[idx])\n",
        "\n",
        "for idx in test_indices:\n",
        "  test_q.append(questions[idx])\n",
        "  test_a.append(answers[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scw4i61Nm_TW",
        "outputId": "9023c937-e255-4919-e78c-99f3fdfd4e99"
      },
      "source": [
        "test_q[:3], test_a[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['사이 즈 업 해서 주세요 \\n',\n",
              "  '캐러멜 드리블 이랑 통 잡아 칩이요 \\n',\n",
              "  '시즌 메뉴 와 함께 구성 되어 있는 세트 메뉴 가 있나요 ? \\n'],\n",
              " ['\\t 네 결제 는 어떻게 도 와 드릴 까요 ? \\n',\n",
              "  '\\t 6700원 결제 도 와 드리겠습니다 \\n',\n",
              "  '\\t 네 치즈 케이크 와 시즌 메뉴 두 잔 으로 구성 된 세트 메뉴 있습니다 \\n'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drXeByqjoLUB"
      },
      "source": [
        "# 토크나이징"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bg1oLpLonN3"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=vocab_size, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t78SQd6pKFo",
        "outputId": "9966e651-8f8e-4624-ba57-1020bfadaaa9"
      },
      "source": [
        "tokenizer.fit_on_texts(train_q + train_a) # 질문과 대답의 모든 내용을 토큰화\n",
        "print(tokenizer.word_index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 1, '\\t': 2, '네': 3, '주세요': 4, '로': 5, '아메리카노': 6, '는': 7, '에': 8, '아이스': 9, '도': 10, '요': 11, '잔': 12, '이': 13, '한': 14, '드릴': 15, '까요': 16, '은': 17, '입니다': 18, '사이즈': 19, '가': 20, '있나요': 21, '결제': 22, '수': 23, '하나': 24, '있습니다': 25, '와': 26, '드시고': 27, '해주세요': 28, '할게요': 29, '으로': 30, '라테': 31, '추가': 32, '따뜻한': 33, '주문': 34, '사용': 35, '음료': 36, '되나요': 37, '여기': 38, '아니요': 39, '거': 40, '얼마': 41, '개': 42, '그럼': 43, '카드': 44, '랑': 45, '드리겠습니다': 46, '케이크': 47, '어떤': 48, '걸': 49, '포인트': 50, '가시나요': 51, '한잔': 52, '할인': 53, '적립': 54, '다': 55, '커피': 56, '더': 57, '인가요': 58, '쿠폰': 59, '가요': 60, '드릴게요': 61, '티': 62, '건': 63, '가능합니다': 64, '알겠습니다': 65, '에서': 66, '가능한가요': 67, '매장': 68, '를': 69, '진동': 70, '면': 71, '벨': 72, '안': 73, '번호': 74, '만': 75, '에요': 76, '메뉴': 77, '하나요': 78, '디카': 79, '페인': 80, '건가': 81, '샷': 82, '있어요': 83, '됩니다': 84, '테이크아웃': 85, '예요': 86, '스무디': 87, '게': 88, '카페라테': 89, '두': 90, '같이': 91, '자몽': 92, '하고': 93, '치즈케이크': 94, '제일': 95, '뭐': 96, '카페모카': 97, '기프티콘': 98, '세트': 99, '지금': 100, '종류': 101, '해서': 102, '업': 103, '먹고': 104, '휘핑크림': 105, '이랑': 106, '머핀': 107, '몇': 108, '어떻게': 109, '현금영수증': 110, '원': 111, '해드리겠습니다': 112, '하실': 113, '까지': 114, '초코': 115, '주스': 116, '화이트': 117, '프라푸치노': 118, '해': 119, '시럽': 120, '테이크': 121, '아웃': 122, '많이': 123, '베이글': 124, '2': 125, '다른': 126, '울리면': 127, '가능하세요': 128, '1': 129, '텀블러': 130, '저': 131, '갈': 132, '컵': 133, '주시': 134, '할': 135, '바닐라': 136, '크림': 137, '추천': 138, '없으신': 139, '4500원': 140, '해드릴게요': 141, '500원': 142, '총': 143, '포장': 144, '딸기': 145, '중': 146, '혹시': 147, '판매': 148, '밀크': 149, '영수증': 150, '과': 151, '둘': 152, '스콘': 153, '아': 154, '잘': 155, '찍어주세요': 156, '계산': 157, '루이보스': 158, '정도': 159, '맛': 160, '원두': 161, '필요한': 162, '올려': 163, '가실': 164, '준비': 165, '없으세요': 166, '어디': 167, '자리': 168, '얼마나': 169, '오늘': 170, '휘핑': 171, '얼음': 172, '그냥': 173, '화장실': 174, '담아': 175, '서': 176, '라지': 177, '있을까요': 178, '과일': 179, '카페인': 180, '것': 181, '가격': 182, '인데': 183, '있으세요': 184, '있으신': 185, '저희': 186, '치즈': 187, '플랫': 188, '죠': 189, '시즌': 190, '넣어': 191, '고객': 192, '님': 193, '알려': 194, '도장': 195, '되죠': 196, '그러면': 197, '티라미슈': 198, '변경': 199, '페이': 200, '데': 201, '카푸치노': 202, '주실': 203, '고': 204, '샌드위치': 205, '티라미수': 206, '현금': 207, '그렇게': 208, '쿠키': 209, '차갑게': 210, '아니오': 211, '일회용': 212, '따뜻하게': 213, '무료': 214, '이나': 215, '말차': 216, '나가요': 217, '영업': 218, '있는데': 219, '생크림': 220, '이드': 221, '을': 222, '유자차': 223, '조각': 224, '아뇨': 225, '유리잔': 226, '뭘': 227, '와주세요': 228, '10시': 229, '필요하신': 230, '해드릴까': 231, '가능하십니다': 232, '가세': 233, '말씀': 234, '완료': 235, '되었습니다': 236, '하시겠어요': 237, '선택': 238, '부탁드릴게요': 239, '때': 240, '핫초코': 241, '파나요': 242, '블루베리': 243, '담아주세요': 244, '건데': 245, '차가운': 246, '엔': 247, '뭔가': 248, '주': 249, '주시나요': 250, '넣어주세요': 251, '찾으러': 252, '될까': 253, '우유': 254, '부탁드려요': 255, '담아주실': 256, '스몰': 257, '10': 258, '가능할까': 259, '괜찮아요': 260, '키위': 261, '주차': 262, '조금': 263, '없나요': 264, '에스프레소': 265, '입력': 266, '카페라떼': 267, '페퍼민트': 268, '그리고': 269, '멤버십': 270, '앞': 271, '피지': 272, '제': 273, '녹차': 274, '바코드': 275, '와이파이': 276, '비밀번호': 277, '차': 278, '만들어': 279, '캐리어': 280, '겨울': 281, '시': 282, '있는': 283, '에는': 284, '쪽': 285, '잠시': 286, '10분': 287, '에서는': 288, '머그컵': 289, '않습니다': 290, '그럼요': 291, '하시면': 292, '하시는': 293, '가능해요': 294, '4000원': 295, '나': 296, '맞으세요': 297, '2000원': 298, '오시': 299, '레드': 300, '벨벳': 301, '언제': 302, '맛있는': 303, '모았는데': 304, '써도': 305, '하겠습니다': 306, '카카오': 307, '사이': 308, '즈': 309, '기다려야': 310, '의': 311, '개인': 312, '칩': 313, '적게': 314, '그': 315, '팥빙수': 316, '아이리쉬': 317, '있죠': 318, '갈게요': 319, '허니': 320, '브레드': 321, '직접': 322, '우려': 323, '시간': 324, '계절': 325, '부탁드립니다': 326, '모카': 327, '아아': 328, '만들어주세요': 329, '차는': 330, '캐러멜': 331, '들고': 332, '통신사': 333, '나갈': 334, '딸기스무디': 335, '생': 336, '모으면': 337, '마실': 338, '양': 339, '다음': 340, '번': 341, '이번': 342, '좀': 343, '하시나요': 344, '라떼': 345, '잔이요': 346, '걸려요': 347, '주시겠어요': 348, '어니언': 349, '접시': 350, '빵': 351, '민트': 352, '올려주세요': 353, '그건': 354, '쓸': 355, '하면': 356, '프라': 357, '페': 358, '맛있어요': 359, '걸릴까': 360, '충전': 361, '따로': 362, '있고': 363, '뜨거운': 364, '감귤': 365, '인절미': 366, '쏙쏙': 367, '붕어빵': 368, '고소한': 369, '품절': 370, '인': 371, '엘지': 372, '파이': 373, '전': 374, '대체': 375, '무엇': 376, '두유': 377, '없습니다': 378, '잘나가요': 379, '불가능합니다': 380, '괜찮으세요': 381, '300원': 382, '기다려주세요': 383, '내': 384, '상': 385, '드리고': 386, '이신': 387, '재료': 388, '바로': 389, '손님': 390, '하지': 391, '안됩니다': 392, '돼요': 393, '블랙': 394, '찍어': 395, '괜찮으신': 396, '픽업': 397, '해드려요': 398, '제공': 399, '오세요': 400, '받았습니다': 401, '플레인': 402, '기본': 403, '오후': 404, '따듯': 405, '안되고': 406, '톨': 407, '데워': 408, '5분': 409, '되셨습니다': 410, '9500원': 411, '카운터': 412, '문': 413, '없으시고요': 414, '보다': 415, '드려요': 416, '머그잔': 417, '해주시면': 418, '바꿔': 419, '5000원': 420, '점': 421, '부터': 422, '마감': 423, '앉아있다': 424, '가면': 425, '잘나가는': 426, '가져갈': 427, '기프트': 428, '콘': 429, '가능하나요': 430, '브런치': 431, '가져갈게요': 432, '빨대': 433, '아메리카': 434, '부탁': 435, '해요': 436, '나오나요': 437, '나중': 438, 'kt': 439, '더블': 440, '위': 441, '마시다가': 442, '들고나': 443, '그란': 444, '사이드': 445, '날씨': 446, '먹어요': 447, '받으려면': 448, '30': 449, '자바': 450, '빼고요': 451, '량': 452, '조절': 453, '걸리나요': 454, '십': 455, '시오': 456, '마카롱': 457, '남아있나요': 458, '하려고': 459, '대면': 460, '데워주실': 461, '줘요': 462, '남은': 463, '삼': 464, '성': 465, '에만': 466, '나오는': 467, '후': 468, '오면': 469, '받을': 470, '타서': 471, '연하게': 472, '만들어주실': 473, '모바일': 474, '함께': 475, '드리블': 476, '통': 477, '잡아': 478, '깔아주세요': 479, '전부': 480, '돼도': 481, '해주죠': 482, '안전히': 483, '있게': 484, '마시다': 485, '거니': 486, '없을까요': 487, '아이스커피': 488, '가능하죠': 489, '적은': 490, '숏': 491, '했어요': 492, '업은': 493, '삼성': 494, '덜': 495, '넣어주실': 496, '그린': 497, '20': 498, '말고': 499, '새로': 500, '적고': 501, '사람': 502, '당': 503, '씩': 504, '시켜야': 505, '아닌': 506, '들어간': 507, '휴대폰': 508, '마시려는데': 509, '명': 510, '창가': 511, '앉을': 512, '들어있지': 513, '않은': 514, '차감': 515, '으로는': 516, '없이': 517, '줄': 518, '스타벅스': 519, '당근': 520, '캐머': 521, '마일': 522, '물티슈': 523, '챙겨': 524, '큰': 525, '쿠앤크': 526, '치노': 527, '미지근한': 528, '물': 529, '그거': 530, '저번': 531, '와서': 532, '먹은': 533, '미숫가루': 534, '없네요': 535, '4': 536, '아직': 537, '런치': 538, '코': 539, '찡할': 540, '만큼': 541, '동시': 542, '가겠습니다': 543, '달': 544, '지': 545, '않나요': 546, '마키아토': 547, '들어가죠': 548, '먹을': 549, '맴버쉽': 550, '옮겨줄': 551, '콘센트': 552, '주시는데': 553, '들어가있나요': 554, '키': 555, '오스': 556, '크에서': 557, '되네요': 558, '나왔어요': 559, '해주신': 560, '3': 561, '어우러지는': 562, '업도': 563, '진하게': 564, '젤': 565, '좋아하는': 566, '리저브': 567, '처음': 568, '눌렀습니다': 569, '쓴가요': 570, '기존': 571, '통합': 572, '시킬': 573, '수도': 574, '레몬': 575, '분': 576, '들은': 577, '기계': 578, '인식': 579, '안되는데요': 580, '2만': 581, '밸': 582, '휘핑빼': 583, '우선': 584, '물이': 585, '치': 586, '오천': 587, '이요': 588, '먹을게요': 589, '감사합니다': 590, '하나같이': 591, '빅사': 592, '이즈': 593, '기프트카드': 594, '올라가는': 595, '작은': 596, '실내': 597, '가져왔는데': 598, '평소': 599, '주로': 600, '마시는데요': 601, '그런데': 602, '중간': 603, '대신': 604, '유로': 605, '빼주세요': 606, '빼주실': 607, '너무': 608, '달아서': 609, '싫은데': 610, '있으면': 611, '케익': 612, '교환': 613, '권': 614, '바꿀': 615, '로는': 616, '맛있나요': 617, '오픈': 618, '챙겨주세요': 619, '단것': 620, '별로': 621, '와는': 622, '해주시': 623, '카페': 624, '요금': 625, '바꿔서': 626, '올해': 627, '부터는': 628, '점포': 629, '1회': 630, '용을': 631, '바닥': 632, '청소': 633, '해야': 634, '죄송합니다': 635, '요새': 636, '라이트': 637, '5500원': 638, '바나나': 639, '파인애플': 640, '가지': 641, '계시다가': 642, '가져가세요': 643, '레귤러': 644, '14': 645, '나갑니다': 646, '팔려요': 647, '적용': 648, '9300원': 649, '규정': 650, '인기': 651, '기다려': 652, '단체': 653, '작아서': 654, '들어가요': 655, '6600원': 656, '팔렸어요': 657, '음식': 658, '이라': 659, '안되세요': 660, '되어': 661, '1만': 662, '1천': 663, '복도': 664, '나가시': 665, '보여요': 666, '가시는': 667, '괜찮으실까': 668, '8000원': 669, '드립니다': 670, '왼쪽': 671, '보시': 672, '7천원': 673, '만들고': 674, '진할': 675, '다시': 676, '해주시겠어요': 677, '드실': 678, '드리도록': 679, '되어있습니다': 680, '보여주세요': 681, '손잡이': 682, '투': 683, '들어가는데': 684, '대로': 685, '사항': 686, '곳': 687, '고르시면': 688, '보통': 689, '여자': 690, '분들': 691, '특정': 692, '선호': 693, '아니면': 694, '예': 695, '가체': 696, '프': 697, '냉동': 698, '제품': 699, '이고': 700, '다해': 701, '10900원': 702, '하프': 703, '되셔서': 704, '또': 705, '50': 706, '4천원': 707, '18000원': 708, '꽃': 709, '15000': 710, '1500원': 711, '어떠세요': 712, '500': 713, '기다리시면': 714, '안내': 715, '성분': 716, '들어가지': 717, '번만': 718, '테이블': 719, '하게': 720, '아예': 721, '빼는': 722, '최대한': 723, '하시고': 724, '잔액': 725, '3천': 726, '드렸고': 727, '이리': 728, '드릴가요': 729, '하세요': 730, '오전': 731, '이전': 732, '오셔서': 733, '한정': 734, '라': 735, '동일하게': 736, '저기': 737, '가져오시면': 738, '2시': 739, '가지러': 740, '곡물': 741, '가루': 742, '넣어서': 743, '고소하고': 744, '받으러': 745, '세': 746, '들어갑니다': 747, '호두': 748, '어울려요': 749, '적어주세요': 750, '층': 751, '나오면': 752, '로만': 753, '앉아': 754, '계시': 755, '가져다': 756, '기다리세요': 757, '오른쪽': 758, '벽쪽': 759, '건물': 760, '뒤': 761, '주차장': 762, '들어가있습니다': 763, '휴대': 764, '알려주시면': 765, '가능합니다만': 766, '천': 767, '올라가게': 768, '상큼': 769, '어울립니다': 770, '죄송합니다만': 771, '방금': 772, '떨어졌어요': 773, '유효': 774, '기간': 775, '라면': 776, '딱': 777, '맞게': 778, '오셨네요': 779, '원하시는': 780, '내리는': 781, '방법': 782, '대략': 783, '걸립니다': 784, '고맙습니다': 785, '쓴맛': 786, '없고': 787, '산미': 788, '들': 789, '향': 790, '나죠': 791, '합쳐': 792, '꽂아': 793, '6000원': 794, '이에요': 795, '밀려서': 796, '7분': 797, '걸릴': 798, '앞쪽': 799, '눌러주세요': 800, '불러': 801, '뜨거운건': 802, '할까': 803, '다모아': 804, '커피한잔': 805, '필요하세요': 806, '해드려도': 807, '괜찮을까요': 808, '떨어져서': 809, '어렵습니다': 810, '신': 811, '꺼': 812, '되는': 813, '8800원': 814, '해드렸습니다': 815, '정책': 816, '불가능하고': 817, '나가실': 818, '하시겠습니까': 819, '필요': 820, '다른거': 821, '필요한거': 822, '현재': 823, '법적': 824, '금지': 825, '종이': 826, '써져있습니다': 827, '한테': 828, '보여주시고': 829, '확인': 830, '버튼': 831, '누르면': 832, '요즘': 833, '없어요': 834, '다크': 835, '초콜릿': 836, '어우러진': 837, '달콤한': 838, '하셨나요': 839, '죄송하지만': 840, '과테말라': 841, '케냐': 842, '섞은': 843, '마이크로': 844, '블렌드': 845, '5천': 846, '필요하신가요': 847, '되세요': 848, '가시는거세요': 849, '7000원': 850, '포크': 851, '들어갔어요': 852, '4100원': 853, '2500원': 854, '당연하죠': 855, '팔려서요': 856, '나온': 857, '오곡': 858, '5000': 859, '그중': 860, '4500': 861, '가능한데': 862, '이상': 863, '9시': 864, '열어요': 865, '12시': 866, '까지라': 867, '드리면': 868, '되셨고': 869, '아주': 870, '단맛': 871, '아닌데요': 872, '라임': 873, '하단': 874, '적혀있습니다': 875, '합니다': 876, '되면': 877}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyX1EUQepYJZ"
      },
      "source": [
        "정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3k-H27bqG4_",
        "outputId": "55633051-9a6f-4297-f16a-bd33788cf543"
      },
      "source": [
        "train_q_seq = tokenizer.texts_to_sequences(train_q)\n",
        "train_a_seq = tokenizer.texts_to_sequences(train_a)\n",
        "\n",
        "test_q_seq  = tokenizer.texts_to_sequences(test_q)\n",
        "test_a_seq  = tokenizer.texts_to_sequences(test_a)\n",
        "\n",
        "train_q_seq[:3], train_a_seq[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[85, 12, 30, 4, 1], [3, 239, 1], [3, 300, 301, 47, 4, 1]],\n",
              " [[2, 627, 628, 629, 73, 66, 630, 631, 35, 113, 23, 378, 1],\n",
              "  [2, 57, 162, 63, 139, 60, 1],\n",
              "  [2, 36, 7, 227, 5, 15, 16, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNxTApmaqa8a"
      },
      "source": [
        "패딩 후 최종 데이터 마련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mzzXyq2quqx"
      },
      "source": [
        "# 문장의 최대길이 64로 설정 했음!\n",
        "X_train = pad_sequences(\n",
        "    train_q_seq,\n",
        "    value=0,\n",
        "    padding='pre',\n",
        "    maxlen=64\n",
        ")\n",
        "\n",
        "y_train = pad_sequences(\n",
        "    train_a_seq,\n",
        "    value=0,\n",
        "    padding='post',\n",
        "    maxlen=65 # <sos>, <eos>\n",
        ")\n",
        "\n",
        "X_test = pad_sequences( test_q_seq, value=0, padding='pre', maxlen=64 )\n",
        "y_test = pad_sequences( test_a_seq, value=0, padding='post', maxlen=65 )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_putRvhsNA-",
        "outputId": "49a6eefb-688a-4fec-df99-abf615f2cf05"
      },
      "source": [
        "X_train[0], y_train[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0, 85, 12, 30,  4,  1], dtype=int32),\n",
              " array([  2, 627, 628, 629,  73,  66, 630, 631,  35, 113,  23, 378,   1,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
              "       dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-K8I7iJsQIR"
      },
      "source": [
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1024).batch(32).prefetch(1024) # prefetch : 데이터를 미리 저장할 공간을 의미\n",
        "test_ds  = tf.data.Dataset.from_tensor_slices((X_test, y_test)).batch(1).prefetch(1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTEFKuXXtszt"
      },
      "source": [
        "# 학습 환경 정의\n",
        "모델 생성, 손실 함수, 최적화 알고리즘, 평가지표 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqnsbykHwiuV"
      },
      "source": [
        "# 모델 생성\n",
        "model = Seq2seq(\n",
        "    sos=tokenizer.word_index[\"\\t\"],\n",
        "    eos=tokenizer.word_index[\"\\n\"]\n",
        ")\n",
        "\n",
        "# Loss 선정. 정수 인코딩된 결과를 t로 사용, softmax 이용한 정수값을 예측으로 쓰니까 sparse_categorical_crossentropy\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 모델 평가 방식\n",
        "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcnZVaa-yb_-"
      },
      "source": [
        "# 학습 루프 동작"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4RHBVRVyhut",
        "outputId": "c08d6b16-4844-48d2-c17d-2af49797b7f3"
      },
      "source": [
        "EPOCHS = 200\n",
        "for epoch in range(EPOCHS):\n",
        "  for seqs, labels in train_ds:\n",
        "    train_step(model, seqs, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
        "  \n",
        "  print(\"Epoch : {}, Loss : {:.3f}, Accuracy : {:.3f}\".format(epoch + 1,\n",
        "                                                      train_loss.result(),\n",
        "                                                      train_accuracy.result() * 100))\n",
        "  \n",
        "  train_loss.reset_states()\n",
        "  train_accuracy.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"strided_slice_1:0\", shape=(32, 64), dtype=int32)\n",
            "Tensor(\"strided_slice_1:0\", shape=(32, 64), dtype=int32)\n",
            "Tensor(\"strided_slice_1:0\", shape=(16, 64), dtype=int32)\n",
            "Epoch : 1, Loss : 3.192, Accuracy : 83.109\n",
            "Epoch : 2, Loss : 0.605, Accuracy : 90.836\n",
            "Epoch : 3, Loss : 0.575, Accuracy : 91.109\n",
            "Epoch : 4, Loss : 0.562, Accuracy : 91.094\n",
            "Epoch : 5, Loss : 0.552, Accuracy : 91.164\n",
            "Epoch : 6, Loss : 0.540, Accuracy : 91.090\n",
            "Epoch : 7, Loss : 0.544, Accuracy : 91.090\n",
            "Epoch : 8, Loss : 0.534, Accuracy : 91.137\n",
            "Epoch : 9, Loss : 0.530, Accuracy : 91.176\n",
            "Epoch : 10, Loss : 0.521, Accuracy : 91.184\n",
            "Epoch : 11, Loss : 0.515, Accuracy : 91.328\n",
            "Epoch : 12, Loss : 0.501, Accuracy : 91.293\n",
            "Epoch : 13, Loss : 0.487, Accuracy : 91.477\n",
            "Epoch : 14, Loss : 0.471, Accuracy : 91.754\n",
            "Epoch : 15, Loss : 0.457, Accuracy : 91.992\n",
            "Epoch : 16, Loss : 0.445, Accuracy : 92.238\n",
            "Epoch : 17, Loss : 0.431, Accuracy : 92.391\n",
            "Epoch : 18, Loss : 0.429, Accuracy : 92.492\n",
            "Epoch : 19, Loss : 0.425, Accuracy : 92.496\n",
            "Epoch : 20, Loss : 0.419, Accuracy : 92.492\n",
            "Epoch : 21, Loss : 0.415, Accuracy : 92.547\n",
            "Epoch : 22, Loss : 0.410, Accuracy : 92.621\n",
            "Epoch : 23, Loss : 0.404, Accuracy : 92.613\n",
            "Epoch : 24, Loss : 0.396, Accuracy : 92.688\n",
            "Epoch : 25, Loss : 0.392, Accuracy : 92.699\n",
            "Epoch : 26, Loss : 0.394, Accuracy : 92.762\n",
            "Epoch : 27, Loss : 0.388, Accuracy : 92.793\n",
            "Epoch : 28, Loss : 0.385, Accuracy : 92.836\n",
            "Epoch : 29, Loss : 0.386, Accuracy : 92.879\n",
            "Epoch : 30, Loss : 0.379, Accuracy : 92.879\n",
            "Epoch : 31, Loss : 0.381, Accuracy : 92.953\n",
            "Epoch : 32, Loss : 0.370, Accuracy : 92.945\n",
            "Epoch : 33, Loss : 0.365, Accuracy : 93.023\n",
            "Epoch : 34, Loss : 0.363, Accuracy : 93.035\n",
            "Epoch : 35, Loss : 0.362, Accuracy : 93.047\n",
            "Epoch : 36, Loss : 0.360, Accuracy : 93.172\n",
            "Epoch : 37, Loss : 0.353, Accuracy : 93.203\n",
            "Epoch : 38, Loss : 0.351, Accuracy : 93.195\n",
            "Epoch : 39, Loss : 0.348, Accuracy : 93.273\n",
            "Epoch : 40, Loss : 0.340, Accuracy : 93.262\n",
            "Epoch : 41, Loss : 0.340, Accuracy : 93.328\n",
            "Epoch : 42, Loss : 0.336, Accuracy : 93.371\n",
            "Epoch : 43, Loss : 0.338, Accuracy : 93.449\n",
            "Epoch : 44, Loss : 0.334, Accuracy : 93.445\n",
            "Epoch : 45, Loss : 0.325, Accuracy : 93.523\n",
            "Epoch : 46, Loss : 0.322, Accuracy : 93.543\n",
            "Epoch : 47, Loss : 0.317, Accuracy : 93.555\n",
            "Epoch : 48, Loss : 0.316, Accuracy : 93.602\n",
            "Epoch : 49, Loss : 0.313, Accuracy : 93.695\n",
            "Epoch : 50, Loss : 0.309, Accuracy : 93.707\n",
            "Epoch : 51, Loss : 0.309, Accuracy : 93.777\n",
            "Epoch : 52, Loss : 0.302, Accuracy : 93.848\n",
            "Epoch : 53, Loss : 0.297, Accuracy : 93.883\n",
            "Epoch : 54, Loss : 0.296, Accuracy : 93.898\n",
            "Epoch : 55, Loss : 0.292, Accuracy : 94.051\n",
            "Epoch : 56, Loss : 0.286, Accuracy : 94.090\n",
            "Epoch : 57, Loss : 0.284, Accuracy : 94.125\n",
            "Epoch : 58, Loss : 0.277, Accuracy : 94.184\n",
            "Epoch : 59, Loss : 0.271, Accuracy : 94.250\n",
            "Epoch : 60, Loss : 0.271, Accuracy : 94.242\n",
            "Epoch : 61, Loss : 0.265, Accuracy : 94.352\n",
            "Epoch : 62, Loss : 0.264, Accuracy : 94.469\n",
            "Epoch : 63, Loss : 0.259, Accuracy : 94.500\n",
            "Epoch : 64, Loss : 0.259, Accuracy : 94.582\n",
            "Epoch : 65, Loss : 0.251, Accuracy : 94.668\n",
            "Epoch : 66, Loss : 0.245, Accuracy : 94.793\n",
            "Epoch : 67, Loss : 0.241, Accuracy : 94.906\n",
            "Epoch : 68, Loss : 0.242, Accuracy : 94.949\n",
            "Epoch : 69, Loss : 0.237, Accuracy : 94.945\n",
            "Epoch : 70, Loss : 0.230, Accuracy : 95.223\n",
            "Epoch : 71, Loss : 0.225, Accuracy : 95.227\n",
            "Epoch : 72, Loss : 0.223, Accuracy : 95.414\n",
            "Epoch : 73, Loss : 0.218, Accuracy : 95.406\n",
            "Epoch : 74, Loss : 0.213, Accuracy : 95.559\n",
            "Epoch : 75, Loss : 0.210, Accuracy : 95.562\n",
            "Epoch : 76, Loss : 0.207, Accuracy : 95.711\n",
            "Epoch : 77, Loss : 0.205, Accuracy : 95.801\n",
            "Epoch : 78, Loss : 0.201, Accuracy : 95.844\n",
            "Epoch : 79, Loss : 0.196, Accuracy : 96.062\n",
            "Epoch : 80, Loss : 0.189, Accuracy : 96.168\n",
            "Epoch : 81, Loss : 0.186, Accuracy : 96.254\n",
            "Epoch : 82, Loss : 0.184, Accuracy : 96.375\n",
            "Epoch : 83, Loss : 0.178, Accuracy : 96.398\n",
            "Epoch : 84, Loss : 0.178, Accuracy : 96.504\n",
            "Epoch : 85, Loss : 0.171, Accuracy : 96.676\n",
            "Epoch : 86, Loss : 0.168, Accuracy : 96.723\n",
            "Epoch : 87, Loss : 0.166, Accuracy : 96.793\n",
            "Epoch : 88, Loss : 0.164, Accuracy : 96.785\n",
            "Epoch : 89, Loss : 0.160, Accuracy : 96.926\n",
            "Epoch : 90, Loss : 0.155, Accuracy : 96.996\n",
            "Epoch : 91, Loss : 0.154, Accuracy : 97.016\n",
            "Epoch : 92, Loss : 0.151, Accuracy : 97.109\n",
            "Epoch : 93, Loss : 0.147, Accuracy : 97.230\n",
            "Epoch : 94, Loss : 0.145, Accuracy : 97.285\n",
            "Epoch : 95, Loss : 0.141, Accuracy : 97.281\n",
            "Epoch : 96, Loss : 0.138, Accuracy : 97.371\n",
            "Epoch : 97, Loss : 0.135, Accuracy : 97.457\n",
            "Epoch : 98, Loss : 0.133, Accuracy : 97.457\n",
            "Epoch : 99, Loss : 0.130, Accuracy : 97.562\n",
            "Epoch : 100, Loss : 0.128, Accuracy : 97.609\n",
            "Epoch : 101, Loss : 0.125, Accuracy : 97.621\n",
            "Epoch : 102, Loss : 0.121, Accuracy : 97.684\n",
            "Epoch : 103, Loss : 0.119, Accuracy : 97.707\n",
            "Epoch : 104, Loss : 0.118, Accuracy : 97.746\n",
            "Epoch : 105, Loss : 0.115, Accuracy : 97.809\n",
            "Epoch : 106, Loss : 0.114, Accuracy : 97.887\n",
            "Epoch : 107, Loss : 0.112, Accuracy : 97.840\n",
            "Epoch : 108, Loss : 0.110, Accuracy : 97.887\n",
            "Epoch : 109, Loss : 0.106, Accuracy : 97.906\n",
            "Epoch : 110, Loss : 0.104, Accuracy : 97.988\n",
            "Epoch : 111, Loss : 0.103, Accuracy : 98.020\n",
            "Epoch : 112, Loss : 0.100, Accuracy : 98.016\n",
            "Epoch : 113, Loss : 0.098, Accuracy : 98.129\n",
            "Epoch : 114, Loss : 0.096, Accuracy : 98.133\n",
            "Epoch : 115, Loss : 0.094, Accuracy : 98.113\n",
            "Epoch : 116, Loss : 0.092, Accuracy : 98.184\n",
            "Epoch : 117, Loss : 0.090, Accuracy : 98.223\n",
            "Epoch : 118, Loss : 0.088, Accuracy : 98.211\n",
            "Epoch : 119, Loss : 0.087, Accuracy : 98.270\n",
            "Epoch : 120, Loss : 0.085, Accuracy : 98.270\n",
            "Epoch : 121, Loss : 0.083, Accuracy : 98.328\n",
            "Epoch : 122, Loss : 0.081, Accuracy : 98.371\n",
            "Epoch : 123, Loss : 0.080, Accuracy : 98.387\n",
            "Epoch : 124, Loss : 0.078, Accuracy : 98.395\n",
            "Epoch : 125, Loss : 0.077, Accuracy : 98.430\n",
            "Epoch : 126, Loss : 0.075, Accuracy : 98.461\n",
            "Epoch : 127, Loss : 0.073, Accuracy : 98.527\n",
            "Epoch : 128, Loss : 0.072, Accuracy : 98.520\n",
            "Epoch : 129, Loss : 0.071, Accuracy : 98.551\n",
            "Epoch : 130, Loss : 0.069, Accuracy : 98.543\n",
            "Epoch : 131, Loss : 0.067, Accuracy : 98.617\n",
            "Epoch : 132, Loss : 0.066, Accuracy : 98.625\n",
            "Epoch : 133, Loss : 0.065, Accuracy : 98.633\n",
            "Epoch : 134, Loss : 0.063, Accuracy : 98.684\n",
            "Epoch : 135, Loss : 0.062, Accuracy : 98.707\n",
            "Epoch : 136, Loss : 0.060, Accuracy : 98.695\n",
            "Epoch : 137, Loss : 0.059, Accuracy : 98.773\n",
            "Epoch : 138, Loss : 0.058, Accuracy : 98.781\n",
            "Epoch : 139, Loss : 0.057, Accuracy : 98.801\n",
            "Epoch : 140, Loss : 0.056, Accuracy : 98.832\n",
            "Epoch : 141, Loss : 0.054, Accuracy : 98.855\n",
            "Epoch : 142, Loss : 0.052, Accuracy : 98.891\n",
            "Epoch : 143, Loss : 0.051, Accuracy : 98.938\n",
            "Epoch : 144, Loss : 0.050, Accuracy : 98.930\n",
            "Epoch : 145, Loss : 0.049, Accuracy : 98.957\n",
            "Epoch : 146, Loss : 0.048, Accuracy : 98.984\n",
            "Epoch : 147, Loss : 0.047, Accuracy : 99.035\n",
            "Epoch : 148, Loss : 0.045, Accuracy : 99.055\n",
            "Epoch : 149, Loss : 0.044, Accuracy : 99.094\n",
            "Epoch : 150, Loss : 0.043, Accuracy : 99.105\n",
            "Epoch : 151, Loss : 0.042, Accuracy : 99.121\n",
            "Epoch : 152, Loss : 0.041, Accuracy : 99.160\n",
            "Epoch : 153, Loss : 0.041, Accuracy : 99.152\n",
            "Epoch : 154, Loss : 0.040, Accuracy : 99.172\n",
            "Epoch : 155, Loss : 0.038, Accuracy : 99.250\n",
            "Epoch : 156, Loss : 0.038, Accuracy : 99.195\n",
            "Epoch : 157, Loss : 0.036, Accuracy : 99.285\n",
            "Epoch : 158, Loss : 0.035, Accuracy : 99.285\n",
            "Epoch : 159, Loss : 0.034, Accuracy : 99.348\n",
            "Epoch : 160, Loss : 0.033, Accuracy : 99.320\n",
            "Epoch : 161, Loss : 0.032, Accuracy : 99.336\n",
            "Epoch : 162, Loss : 0.031, Accuracy : 99.395\n",
            "Epoch : 163, Loss : 0.030, Accuracy : 99.402\n",
            "Epoch : 164, Loss : 0.030, Accuracy : 99.410\n",
            "Epoch : 165, Loss : 0.030, Accuracy : 99.453\n",
            "Epoch : 166, Loss : 0.028, Accuracy : 99.477\n",
            "Epoch : 167, Loss : 0.028, Accuracy : 99.480\n",
            "Epoch : 168, Loss : 0.027, Accuracy : 99.500\n",
            "Epoch : 169, Loss : 0.026, Accuracy : 99.527\n",
            "Epoch : 170, Loss : 0.025, Accuracy : 99.562\n",
            "Epoch : 171, Loss : 0.025, Accuracy : 99.559\n",
            "Epoch : 172, Loss : 0.024, Accuracy : 99.605\n",
            "Epoch : 173, Loss : 0.023, Accuracy : 99.605\n",
            "Epoch : 174, Loss : 0.022, Accuracy : 99.598\n",
            "Epoch : 175, Loss : 0.022, Accuracy : 99.645\n",
            "Epoch : 176, Loss : 0.021, Accuracy : 99.664\n",
            "Epoch : 177, Loss : 0.021, Accuracy : 99.691\n",
            "Epoch : 178, Loss : 0.020, Accuracy : 99.680\n",
            "Epoch : 179, Loss : 0.019, Accuracy : 99.688\n",
            "Epoch : 180, Loss : 0.019, Accuracy : 99.723\n",
            "Epoch : 181, Loss : 0.018, Accuracy : 99.730\n",
            "Epoch : 182, Loss : 0.017, Accuracy : 99.762\n",
            "Epoch : 183, Loss : 0.017, Accuracy : 99.770\n",
            "Epoch : 184, Loss : 0.016, Accuracy : 99.785\n",
            "Epoch : 185, Loss : 0.016, Accuracy : 99.789\n",
            "Epoch : 186, Loss : 0.016, Accuracy : 99.789\n",
            "Epoch : 187, Loss : 0.015, Accuracy : 99.805\n",
            "Epoch : 188, Loss : 0.014, Accuracy : 99.840\n",
            "Epoch : 189, Loss : 0.014, Accuracy : 99.828\n",
            "Epoch : 190, Loss : 0.013, Accuracy : 99.887\n",
            "Epoch : 191, Loss : 0.013, Accuracy : 99.871\n",
            "Epoch : 192, Loss : 0.013, Accuracy : 99.883\n",
            "Epoch : 193, Loss : 0.012, Accuracy : 99.871\n",
            "Epoch : 194, Loss : 0.012, Accuracy : 99.887\n",
            "Epoch : 195, Loss : 0.012, Accuracy : 99.906\n",
            "Epoch : 196, Loss : 0.011, Accuracy : 99.902\n",
            "Epoch : 197, Loss : 0.011, Accuracy : 99.910\n",
            "Epoch : 198, Loss : 0.011, Accuracy : 99.930\n",
            "Epoch : 199, Loss : 0.010, Accuracy : 99.914\n",
            "Epoch : 200, Loss : 0.010, Accuracy : 99.918\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTEnxczlzPgL"
      },
      "source": [
        "Accuracy가 좋은 이유는?? `Teacher Forcing` 했으니까 좋을 수 밖에.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14LswwakztvV"
      },
      "source": [
        "# 테스트 루프 만들기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVwPJ34Sz3fm",
        "outputId": "6e84d032-0178-476a-941f-b8cfdbbe43df"
      },
      "source": [
        "for test_seq, test_labels in test_ds:\n",
        "  prediction = test_step(model, test_seq)\n",
        "  \n",
        "  test_q = tokenizer.sequences_to_texts(test_seq.numpy()) # 질문\n",
        "  test_a = tokenizer.sequences_to_texts(test_labels.numpy()) # 실제 대답\n",
        "  test_p = tokenizer.sequences_to_texts(prediction.numpy()) # 챗봇의 대답\n",
        "\n",
        "  print(\"______\")\n",
        "  print(\"질문 : \\t{}\".format(test_q))\n",
        "  print(\"실제 대답 : {}\".format(test_a))\n",
        "  print(\"챗봇 대답 : {}\".format(test_p))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "______\n",
            "질문 : \t['사이 즈 업 해서 주세요 \\n']\n",
            "실제 대답 : ['\\t 네 결제 는 어떻게 도 와 드릴 까요 \\n']\n",
            "챗봇 대답 : ['다른 건 필요 없으신 가요 \\n']\n",
            "______\n",
            "질문 : \t['캐러멜 드리블 이랑 통 잡아 \\n']\n",
            "실제 대답 : ['\\t 결제 도 와 드리겠습니다 \\n']\n",
            "챗봇 대답 : ['네 가능합니다 \\n']\n",
            "______\n",
            "질문 : \t['시즌 메뉴 와 함께 되어 있는 세트 메뉴 가 있나요 \\n']\n",
            "실제 대답 : ['\\t 네 치즈 케이크 와 시즌 메뉴 두 잔 으로 세트 메뉴 있습니다 \\n']\n",
            "챗봇 대답 : ['네 시즌 메뉴 가능합니다 \\n']\n",
            "______\n",
            "질문 : \t['아메리카노 1 잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 매장 에서 드시고 가시나요 \\n']\n",
            "챗봇 대답 : ['따뜻한 걸 로 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['그럼 와 아이스 아메리카노 로 할게요 \\n']\n",
            "실제 대답 : ['\\t 더 필요하신 건 없나요 \\n']\n",
            "챗봇 대답 : ['네 결제 는 어떤 것 으로 도 와 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['밀크 티 있나요 \\n']\n",
            "실제 대답 : ['\\t 네 있습니다 \\n']\n",
            "챗봇 대답 : ['아니요 한 사이즈 로만 판매 하고 있습니다 \\n']\n",
            "______\n",
            "질문 : \t['네 기프티콘 여기 있어요 \\n']\n",
            "실제 대답 : ['\\t 아메리카노 기프티콘 사용 되었습니다 \\n']\n",
            "챗봇 대답 : ['네 텀블러 할인 되셔서 4000원 결제 도 와 드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['네 오늘 의 커피 로 주세요 \\n']\n",
            "실제 대답 : ['\\t 네 사이즈 는 어떤 걸 로 주문 넣어 드릴 까요 \\n']\n",
            "챗봇 대답 : ['네 음료 와 카페모카 입니다 \\n']\n",
            "______\n",
            "질문 : \t['포인트 사용 없이 적립 만 할게요 \\n']\n",
            "실제 대답 : ['\\t 네 멤버십 카드 주시 면 도 와 드리겠습니다 \\n']\n",
            "챗봇 대답 : ['매장 에서 드시고 가세 요 \\n']\n",
            "______\n",
            "질문 : \t['네 감사합니다 \\n']\n",
            "실제 대답 : ['\\t 따뜻한 카페라테 한 잔 \\n']\n",
            "챗봇 대답 : ['진동 벨 로 알려 드릴게요 \\n']\n",
            "______\n",
            "질문 : \t['네 아이스 아메리카노 한잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 드시고 가실 건가 요 \\n']\n",
            "챗봇 대답 : ['드시고 가시나요 \\n']\n",
            "______\n",
            "질문 : \t['조금 만 나갈 건데 일회용 컵 에는 요 \\n']\n",
            "실제 대답 : ['\\t 거 면 컵 만 가능하세요 \\n']\n",
            "챗봇 대답 : ['네 고객 님 결제 완료 되었습니다 \\n']\n",
            "______\n",
            "질문 : \t['영업 해요 \\n']\n",
            "실제 대답 : ['\\t 영업 하고 있어요 \\n']\n",
            "챗봇 대답 : ['아이스 아메리카노 포장 이신 가요 \\n']\n",
            "______\n",
            "질문 : \t['디카 페인 아이스 아메리카노 한 잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 디카 페인 아이스 아메리카노 는 기존 에 300원 추가 괜찮으신 가요 \\n']\n",
            "챗봇 대답 : ['둘 다 따뜻한 거 맞으세요 \\n']\n",
            "______\n",
            "질문 : \t['총 \\n']\n",
            "실제 대답 : ['\\t 스콘 두 개 아메리카노 샷 추가 텀블러 할인 해서 입니다 \\n']\n",
            "챗봇 대답 : ['진동 벨 로 알려 드릴게요 \\n']\n",
            "______\n",
            "질문 : \t['카드 로 결제 할게요 \\n']\n",
            "실제 대답 : ['\\t 네 감사합니다 \\n']\n",
            "챗봇 대답 : ['영수증 드릴게요 \\n']\n",
            "______\n",
            "질문 : \t['이 쿠키 는 뭐 예요 \\n']\n",
            "실제 대답 : ['\\t 초코 칩 쿠키 입니다 \\n']\n",
            "챗봇 대답 : ['티 와 주스 가 있습니다 \\n']\n",
            "______\n",
            "질문 : \t['커피 에 샷 추가 가능한가요 \\n']\n",
            "실제 대답 : ['\\t 네 가능합니다 \\n']\n",
            "챗봇 대답 : ['머그잔 에 드릴게요 \\n']\n",
            "______\n",
            "질문 : \t['멤버십 카드 드리고 현금 으로 계산 할게요 \\n']\n",
            "실제 대답 : ['\\t 네 현금영수증 해드릴까 요 \\n']\n",
            "챗봇 대답 : ['네 그건 나 할인 카드 있으세요 \\n']\n",
            "______\n",
            "질문 : \t['아메리카노 톨 사이즈 로 주세요 \\n']\n",
            "실제 대답 : ['\\t 따뜻한 거 로 드릴 까요 \\n']\n",
            "챗봇 대답 : ['다른 건 필요 없으신 가요 \\n']\n",
            "______\n",
            "질문 : \t['네 도 같이 주시겠어요 \\n']\n",
            "실제 대답 : ['\\t 네 아메리카노 4000원 입니다 \\n']\n",
            "챗봇 대답 : ['네 알겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['핫초코 한 잔 아메리카노 사이 즈 업 한 잔 하면 얼마 인가요 \\n']\n",
            "실제 대답 : ['\\t 입니다 \\n']\n",
            "챗봇 대답 : ['7천원 입니다 \\n']\n",
            "______\n",
            "질문 : \t['쿠폰 찍어주세요 \\n']\n",
            "실제 대답 : ['\\t 네 찍어 드릴게요 \\n']\n",
            "챗봇 대답 : ['10 개 다모아 오시 면 커피한잔 드려요 \\n']\n",
            "______\n",
            "질문 : \t['조각 케이크 도 추가 해주시겠어요 \\n']\n",
            "실제 대답 : ['\\t 네 어떤 거 로 드릴 까요 \\n']\n",
            "챗봇 대답 : ['주 문 번호 로 불러 드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['네 여기 서 먹고 갈 거 예요 \\n']\n",
            "실제 대답 : ['\\t 그럼 머그잔 에 드릴게요 \\n']\n",
            "챗봇 대답 : ['네 준비 해드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['혹시 적립 쿠폰 으로 커피 계산 할 수 있나요 \\n']\n",
            "실제 대답 : ['\\t 네 됩니다 \\n']\n",
            "챗봇 대답 : ['네 같이 적립 해 드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['조금 마시다가 갈 거 에요 \\n']\n",
            "실제 대답 : ['\\t 가실 때 말씀 해주시면 테이크 아웃 잔 에 드릴 우선 머그잔 에 드리겠습니다 \\n']\n",
            "챗봇 대답 : ['주문 은 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['삼성 페이 되나요 \\n']\n",
            "실제 대답 : ['\\t 네 가능합니다 \\n']\n",
            "챗봇 대답 : ['네 가능하세요 \\n']\n",
            "______\n",
            "질문 : \t['플랫 화이트 라지 로 주세요 \\n']\n",
            "실제 대답 : ['\\t 네 \\n']\n",
            "챗봇 대답 : ['신 맛 과 고소한 맛 원두 중 에 어떤 걸 로 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['아메리카노 한 잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 네 아메리카노 어떤 걸 로 드릴 까요 \\n']\n",
            "챗봇 대답 : ['아이스 로 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['아메리카노 기프티콘 사용 해주세요 \\n']\n",
            "실제 대답 : ['\\t 바코드 를 앞 에 기계 에 \\n']\n",
            "챗봇 대답 : ['네 알겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['카페 는 몇 시 까지 하나요 \\n']\n",
            "실제 대답 : ['\\t 까지 합니다 \\n']\n",
            "챗봇 대답 : ['정책 상 불가능하고 나가실 때 말씀 해주시면 테이크아웃 잔 으로 바꿔 드릴 수 는 있습니다 \\n']\n",
            "______\n",
            "질문 : \t['티 종류 도 아이스 가능한가요 \\n']\n",
            "실제 대답 : ['\\t 네 고객 님 티 종류 다 아이스 가능합니다 \\n']\n",
            "챗봇 대답 : ['네 포인트 나 할인 됩니다 \\n']\n",
            "______\n",
            "질문 : \t['머핀 은 뭐 가 제일 맛있나요 \\n']\n",
            "실제 대답 : ['\\t 블루베리 머핀 이 잘 나갑니다 \\n']\n",
            "챗봇 대답 : ['루이보스 랑 유자차 있어요 \\n']\n",
            "______\n",
            "질문 : \t['카페 와이파이 비밀번호 수 있을까요 \\n']\n",
            "실제 대답 : ['\\t 입니다 \\n']\n",
            "챗봇 대답 : ['매장 영업 시간 은 12시 까지라 지금 은 테이크아웃 만 가능하세요 \\n']\n",
            "______\n",
            "질문 : \t['아메리카노 두 잔 주문 할게요 \\n']\n",
            "실제 대답 : ['\\t 아메리카노 따뜻한 건가 요 \\n']\n",
            "챗봇 대답 : ['네 고객 님 결제 완료 되었습니다 \\n']\n",
            "______\n",
            "질문 : \t['카페모카 는 따뜻한 거 로 주세요 \\n']\n",
            "실제 대답 : ['\\t 카페모카 위 에 휘핑 올려 드릴 까요 \\n']\n",
            "챗봇 대답 : ['네 더 필요하신 건 없으세요 \\n']\n",
            "______\n",
            "질문 : \t['오늘 의 커피 는 커피 로 하나요 맛 이 \\n']\n",
            "실제 대답 : ['\\t 아 네 오늘 은 과테말라 커피 입니다 \\n']\n",
            "챗봇 대답 : ['네 카운터 쿠폰 도 와 드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['여기 에서 으로 하나요 \\n']\n",
            "실제 대답 : ['\\t 을 하시면 됩니다 \\n']\n",
            "챗봇 대답 : ['네 어떤 걸 로 하시겠습니까 \\n']\n",
            "______\n",
            "질문 : \t['현금 영수증 해주세요 \\n']\n",
            "실제 대답 : ['\\t 네 번호 찍어주세요 \\n']\n",
            "챗봇 대답 : ['네 번호 찍어주세요 \\n']\n",
            "______\n",
            "질문 : \t['스콘 두 포장 해주세요 \\n']\n",
            "실제 대답 : ['\\t 고객 님 데워 드릴 까요 \\n']\n",
            "챗봇 대답 : ['네 준비 해드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['아이스 아메리카노 사이즈 업 해주세요 \\n']\n",
            "실제 대답 : ['\\t 아이스 아메리카노 4000원 입니다 \\n']\n",
            "챗봇 대답 : ['네 알겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['와이파이 되나요 \\n']\n",
            "실제 대답 : ['\\t 와이파이 는 입니다 \\n']\n",
            "챗봇 대답 : ['네 가능합니다 \\n']\n",
            "______\n",
            "질문 : \t['2 잔 주문 하면 얼마 죠 \\n']\n",
            "실제 대답 : ['\\t 7000원 입니다 \\n']\n",
            "챗봇 대답 : ['제 가 있습니다 \\n']\n",
            "______\n",
            "질문 : \t['제 가 커피 를 음료 좀 추천 해주세요 \\n']\n",
            "실제 대답 : ['\\t 그럼 생 과 주스 가 가요 \\n']\n",
            "챗봇 대답 : ['네 텀블러 할인 300원 같이 적립 됩니다 \\n']\n",
            "______\n",
            "질문 : \t['네 찍어주세요 \\n']\n",
            "실제 대답 : ['\\t 네 주문 딸기 스무디 와 쿠키 드릴게요 \\n']\n",
            "챗봇 대답 : ['네 이리 주세요 \\n']\n",
            "______\n",
            "질문 : \t['포인트 적립 해주세요 \\n']\n",
            "실제 대답 : ['\\t 네 번호 입력 부탁드립니다 \\n']\n",
            "챗봇 대답 : ['네 잠시 만 기다려주세요 \\n']\n",
            "______\n",
            "질문 : \t['단체 주문 가능한가요 \\n']\n",
            "실제 대답 : ['\\t 이 죠 \\n']\n",
            "챗봇 대답 : ['와이파이 비밀번호 는 종이 에 써져있습니다 \\n']\n",
            "______\n",
            "질문 : \t['브레드 종류 는 뭐 가 있나요 \\n']\n",
            "실제 대답 : ['\\t 허니 브레드 와 치즈 브레드 가 있습니다 \\n']\n",
            "챗봇 대답 : ['티 음료 와 스무디 에는 카페인 성분 이 들어가지 않습니다 \\n']\n",
            "______\n",
            "질문 : \t['그럼 자몽 차 한잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 따뜻하게 드릴 까요 \\n']\n",
            "챗봇 대답 : ['저 한테 보여주시고 제 가 확인 버튼 누르면 돼요 \\n']\n",
            "______\n",
            "질문 : \t['아이스 프라푸치노 한 잔이요 \\n']\n",
            "실제 대답 : ['\\t 아이스 프라푸치노 사이즈 는 어떻게 드릴 까요 \\n']\n",
            "챗봇 대답 : ['테이크아웃 인가요 \\n']\n",
            "______\n",
            "질문 : \t['밀크 티 에 혹시 우유 가 아니면 우유 이 \\n']\n",
            "실제 대답 : ['\\t 저희 는 우유 을 사용 하고 있어요 \\n']\n",
            "챗봇 대답 : ['네 저기 서 직접 가져오시면 됩니다 \\n']\n",
            "______\n",
            "질문 : \t['그럼 말차 라테 에 잘 케이크 하나 추천 해주시겠어요 \\n']\n",
            "실제 대답 : ['\\t 치즈 케이크 가 잘 같이 주문 하시는 고객 님 \\n']\n",
            "챗봇 대답 : ['네 4000원 입니다 \\n']\n",
            "______\n",
            "질문 : \t['시럽 도 조금 넣어 주실 수 있나요 \\n']\n",
            "실제 대답 : ['\\t 시럽 은 500원 추가 됩니다 \\n']\n",
            "챗봇 대답 : ['네 그렇게 해드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['그럼 두유 로 바꿔서 카페라테 두 잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 카페라테 사이즈 는 어떻게 드릴 까요 \\n']\n",
            "챗봇 대답 : ['네 더 필요한 건 없으세요 \\n']\n",
            "______\n",
            "질문 : \t['치즈 케이크 는 지금 없나요 \\n']\n",
            "실제 대답 : ['\\t 네 치즈케이크 는 지금 다 \\n']\n",
            "챗봇 대답 : ['죄송합니다만 페퍼민트 는 방금 전 에 다 떨어졌어요 \\n']\n",
            "______\n",
            "질문 : \t['카페라테 디카 페인 \\n']\n",
            "실제 대답 : ['\\t 네 \\n']\n",
            "챗봇 대답 : ['주 문 번호 로 불러 드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['하나 랑 아이스 아메리카노 하나 해서 주세요 \\n']\n",
            "실제 대답 : ['\\t 네 더 추가 하실 것 은 없으신 가요 \\n']\n",
            "챗봇 대답 : ['스콘 도 드시고 가시나요 \\n']\n",
            "______\n",
            "질문 : \t['둘 다 톨 사이즈 로 주세요 \\n']\n",
            "실제 대답 : ['\\t 여기 서 드시고 요 \\n']\n",
            "챗봇 대답 : ['드시고 가시나요 \\n']\n",
            "______\n",
            "질문 : \t['화이트 아이스 도 있나요 \\n']\n",
            "실제 대답 : ['\\t 네 있습니다 \\n']\n",
            "챗봇 대답 : ['네 또 더 필요한 거 있으세요 \\n']\n",
            "______\n",
            "질문 : \t['네 여기 텀블러 에 담아주세요 \\n']\n",
            "실제 대답 : ['\\t 고객 님 텀블러 하시면 500원 할인 됩니다 \\n']\n",
            "챗봇 대답 : ['텀블러 할인 드시고 가시나요 \\n']\n",
            "______\n",
            "질문 : \t['적립 하고 있는데 시즌 메뉴 도 하나 만 적립 되나요 \\n']\n",
            "실제 대답 : ['\\t 네 \\n']\n",
            "챗봇 대답 : ['네 가능합니다 \\n']\n",
            "______\n",
            "질문 : \t['아아 주문 가능한가요 \\n']\n",
            "실제 대답 : ['\\t 네 가능합니다 \\n']\n",
            "챗봇 대답 : ['와이파이 비밀번호 는 종이 에 써져있습니다 \\n']\n",
            "______\n",
            "질문 : \t['기프티콘 으로 결제 할게요 \\n']\n",
            "실제 대답 : ['\\t 네 그럼 쿠폰 저 보여주세요 \\n']\n",
            "챗봇 대답 : ['저 한테 보여주시고 제 가 확인 버튼 누르면 돼요 \\n']\n",
            "______\n",
            "질문 : \t['저 카푸치노 로 주문 할게요 \\n']\n",
            "실제 대답 : ['\\t 시럽 은 얼마나 드릴 까요 \\n']\n",
            "챗봇 대답 : ['어떤 거 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['아이스 아메리카노 1 잔 이랑 아이스 카페라테 1 잔 얼마 인가요 \\n']\n",
            "실제 대답 : ['\\t 아이스 아메리카노 1 잔 은 4000원 아이스 카페라테 1 잔 은 5000원 입니다 \\n']\n",
            "챗봇 대답 : ['4500원 입니다 \\n']\n",
            "______\n",
            "질문 : \t['테이크아웃 할게요 \\n']\n",
            "실제 대답 : ['\\t 지금 중 인데 케이크 주문 하시면 아메리카노 한잔 로 드려요 \\n']\n",
            "챗봇 대답 : ['네 번호 입력 해주세요 \\n']\n",
            "______\n",
            "질문 : \t['밀크 티 종류 는 뭐 가 있어요 \\n']\n",
            "실제 대답 : ['\\t 루이보스 두 개 있습니다 \\n']\n",
            "챗봇 대답 : ['피지 와 나 티 종류 가 있습니다 \\n']\n",
            "______\n",
            "질문 : \t['라테 아이스 도 되나요 \\n']\n",
            "실제 대답 : ['\\t 라테 는 돼요 \\n']\n",
            "챗봇 대답 : ['네 그럼요 \\n']\n",
            "______\n",
            "질문 : \t['이 치즈케이크 도 한 조각 주세요 \\n']\n",
            "실제 대답 : ['\\t 여기 서 드실 건가 요 \\n']\n",
            "챗봇 대답 : ['네 총 9500원 결제 해드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['아이스 로 변경 할 추가 요금 이 있나요 \\n']\n",
            "실제 대답 : ['\\t 아이스 음료 는 500원 이 더 \\n']\n",
            "챗봇 대답 : ['네 같이 적립 해 드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['카드 결제 할게요 \\n']\n",
            "실제 대답 : ['\\t 네 카드 받았습니다 \\n']\n",
            "챗봇 대답 : ['네 앞 에 카드 꽃 아 주시 면 됩니다 \\n']\n",
            "______\n",
            "질문 : \t['아이스 아메리카노 두 잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 드시고 가시나요 \\n']\n",
            "챗봇 대답 : ['네 총 8000원 입니다 \\n']\n",
            "______\n",
            "질문 : \t['톨 사이즈 로 주문 할게요 \\n']\n",
            "실제 대답 : ['\\t 네 계산 도 와 드리겠습니다 \\n']\n",
            "챗봇 대답 : ['네 알겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['초코 머핀 도 하나 추가 해주세요 \\n']\n",
            "실제 대답 : ['\\t 초코 머핀 어떤 걸 로 드릴 까요 \\n']\n",
            "챗봇 대답 : ['네 총 9500원 결제 해드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['얼마 인가요 \\n']\n",
            "실제 대답 : ['\\t 5천 원 입니다 \\n']\n",
            "챗봇 대답 : ['플랫 화이트 4500원 입니다 \\n']\n",
            "______\n",
            "질문 : \t['그러면 예 가체 주세요 \\n']\n",
            "실제 대답 : ['\\t 아메리카노 안 분 들 도 많이 선택 하세요 \\n']\n",
            "챗봇 대답 : ['따뜻한 것 으로 드릴가요 \\n']\n",
            "______\n",
            "질문 : \t['여기 있습니다 \\n']\n",
            "실제 대답 : ['\\t 네 확인 되셨고 되면 진동 벨 거 예요 \\n']\n",
            "챗봇 대답 : ['손님 지금 15000 포인트 있으신 데 사용 해 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['커피 캐리어 도 주실 수 있나요 \\n']\n",
            "실제 대답 : ['\\t 네 캐리어 에 담아 드릴게요 \\n']\n",
            "챗봇 대답 : ['개인 컵 사이즈 가 작아서 음료 가 다 안 들어가요 \\n']\n",
            "______\n",
            "질문 : \t['따뜻한 밀크 티 주세요 \\n']\n",
            "실제 대답 : ['\\t 네 \\n']\n",
            "챗봇 대답 : ['드시고 가시나요 \\n']\n",
            "______\n",
            "질문 : \t['네 두 개 함께 \\n']\n",
            "실제 대답 : ['\\t 네 감사합니다 \\n']\n",
            "챗봇 대답 : ['네 시럽 넣어 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['카페라테 한 잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 카페라테 따뜻한 걸 로 드릴 까요 \\n']\n",
            "챗봇 대답 : ['네 카페라떼 컵 사이즈 는 뭘 로 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['네 차가운 걸 로 주세요 \\n']\n",
            "실제 대답 : ['\\t 4500원 입니다 \\n']\n",
            "챗봇 대답 : ['네 단체 주문 은 재료 추가 불가능합니다 \\n']\n",
            "______\n",
            "질문 : \t['라이트 한 맛 의 아이스 아메리카노 요 \\n']\n",
            "실제 대답 : ['\\t 네 저희 메뉴 에요 \\n']\n",
            "챗봇 대답 : ['네 밀크 티 와 드리겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['지금 되나요 \\n']\n",
            "실제 대답 : ['\\t 는 계절 메뉴 라 지금 은 판매 하지 않습니다 \\n']\n",
            "챗봇 대답 : ['네 가능합니다 \\n']\n",
            "______\n",
            "질문 : \t['사이즈 업 되나요 \\n']\n",
            "실제 대답 : ['\\t 네 \\n']\n",
            "챗봇 대답 : ['네 가능합니다 \\n']\n",
            "______\n",
            "질문 : \t['아뇨 그냥 주세요 \\n']\n",
            "실제 대답 : ['\\t 할인 카드 도 안 하시나요 \\n']\n",
            "챗봇 대답 : ['결제 해드릴게요 \\n']\n",
            "______\n",
            "질문 : \t['치즈 브레드 에 생크림 을 수 는 없나요 \\n']\n",
            "실제 대답 : ['\\t 500원 의 추가 이 괜찮으세요 \\n']\n",
            "챗봇 대답 : ['네 죄송하지만 말차 케이크 는 품절 되었습니다 \\n']\n",
            "______\n",
            "질문 : \t['멤버십 할인 되나요 \\n']\n",
            "실제 대답 : ['\\t 네 멤버십 할인 하시면 10 할인 됩니다 \\n']\n",
            "챗봇 대답 : ['네 가능합니다 \\n']\n",
            "______\n",
            "질문 : \t['이 카드 로 결제 해주세요 \\n']\n",
            "실제 대답 : ['\\t 네 결제 도 와 드릴게요 \\n']\n",
            "챗봇 대답 : ['네 알겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['네 카드 여기 요 \\n']\n",
            "실제 대답 : ['\\t 적립 쿠폰 있으세요 \\n']\n",
            "챗봇 대답 : ['주문 이 밀려서 7분 정도 걸릴 거 예요 \\n']\n",
            "______\n",
            "질문 : \t['티라미수 케이크 도 주세요 \\n']\n",
            "실제 대답 : ['\\t 적립 카드 있으신 가요 \\n']\n",
            "챗봇 대답 : ['네 알겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['아니요 테이크아웃 이 요 \\n']\n",
            "실제 대답 : ['\\t 네 포인트 적립 하시나요 \\n']\n",
            "챗봇 대답 : ['네 알겠습니다 \\n']\n",
            "______\n",
            "질문 : \t['아이스 아메리카노 하나 랑 녹차 라테 주세요 \\n']\n",
            "실제 대답 : ['\\t 녹차 라테 도 아이스 로 드릴 까요 \\n']\n",
            "챗봇 대답 : ['네 더 필요하신 건 없으세요 \\n']\n",
            "______\n",
            "질문 : \t['매장 에서 먹고 갈 거 예요 \\n']\n",
            "실제 대답 : ['\\t 할인 카드 있으신 가요 \\n']\n",
            "챗봇 대답 : ['포크 는 몇 개 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['아메리카노 한잔 주세요 \\n']\n",
            "실제 대답 : ['\\t 따뜻한 걸 로 드릴 까요 \\n']\n",
            "챗봇 대답 : ['드시고 가시나요 \\n']\n",
            "______\n",
            "질문 : \t['을 \\n']\n",
            "실제 대답 : ['\\t 이라 \\n']\n",
            "챗봇 대답 : ['따뜻한 것 과 아이스 중 에 무엇 을 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['바닐라 라테 도 하나 주세요 \\n']\n",
            "실제 대답 : ['\\t 바닐라 라테 따뜻한 거 요 \\n']\n",
            "챗봇 대답 : ['네 더 필요한 건 없으세요 \\n']\n",
            "______\n",
            "질문 : \t['네 2 층 이 \\n']\n",
            "실제 대답 : ['\\t 네 2 층 에 자리 \\n']\n",
            "챗봇 대답 : ['네 결제 는 어떤 것 으로 도 와 드릴 까요 \\n']\n",
            "______\n",
            "질문 : \t['하시나요 \\n']\n",
            "실제 대답 : ['\\t 네 입니다 \\n']\n",
            "챗봇 대답 : ['네 가능합니다 \\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnQXNDWa0CjZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}