{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01. 텍스트 다루기",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u7u1JhmiVKW"
      },
      "source": [
        "# Tokenization (토큰화) 이론\n",
        "어떤 텍스트에서 어디까지가 문장, 어디까지가 단어인지 나눠주는 과정\n",
        "* 문장 토큰화( Sentence Tokenization )\n",
        "* 단어 토큰화( Word Tokenization )\n",
        "* 음절 토큰화( Subword Tokenization )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vBw7Sq_iu5t"
      },
      "source": [
        "## English Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGb0Pusai4k-"
      },
      "source": [
        "sample_text=\"I never thought through love we'd be. Making one as lovely as she. But isn't she lovely made from love.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltXkTrK8i5uI"
      },
      "source": [
        "문장 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKKLEtbYjDti",
        "outputId": "a3e2cf2e-72de-4b46-e5a9-e62cd079464b"
      },
      "source": [
        "# 단순하게 온점을 이용해서 잘라내기\n",
        "tokenized_sentence = sample_text.split(\". \")\n",
        "tokenized_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"I never thought through love we'd be\",\n",
              " 'Making one as lovely as she',\n",
              " \"But isn't she lovely made from love.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ9CKv7mjTES"
      },
      "source": [
        "단어 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87uAxU6WjXvL",
        "outputId": "258169b8-6bdb-4790-c98c-94831e3f6334"
      },
      "source": [
        "tokenized_word = sample_text.split()\n",
        "tokenized_word"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I',\n",
              " 'never',\n",
              " 'thought',\n",
              " 'through',\n",
              " 'love',\n",
              " \"we'd\",\n",
              " 'be.',\n",
              " 'Making',\n",
              " 'one',\n",
              " 'as',\n",
              " 'lovely',\n",
              " 'as',\n",
              " 'she.',\n",
              " 'But',\n",
              " \"isn't\",\n",
              " 'she',\n",
              " 'lovely',\n",
              " 'made',\n",
              " 'from',\n",
              " 'love.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5fGa9DFjfG5"
      },
      "source": [
        "## 띄어쓰기(공백)로만 영어 문장 내 단어를 구분할 때의 문제점\n",
        "\n",
        "* We're Avengers!! : `[We're, Avengers!!]`\n",
        "* We are Avengers!! : `[We, are, Avengers!!]`\n",
        "* We are Avengers : `[We, are, Avengers]`\n",
        "\n",
        "단순하게 공백으로만 토큰화를 수행하면, 사람은 같은 문장이라는 것을 인지할 수 있으나, 하지만 기계는 위 세 문장이 다른 문장이라고 판단."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PA3iN7dMnVGc"
      },
      "source": [
        "### 그럼 특수문자를 제거하면?\n",
        "* `[We, re, Avengers]`\n",
        "* `[We, are, Avengers]`\n",
        "* `[We, are, AVengers]`\n",
        "\n",
        "특수문자가 중요한 의미를 가지는 경우에도 특수문자를 제거하면?\n",
        "* $12.45 : `[12, 45]`\n",
        "* Mr. So : `[Mr, So]`\n",
        "* Mrs. Kim : `[Mrs, Kim]`\n",
        "* 192.168.0.1 : `[192, 168, 0, 1]`\n",
        "* Ph.D : `[Ph, D]`\n",
        "\n",
        "특수문자가 중요한 역할을 하는 경우에는 별로 효용적이지 못한 것 같다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qn9LqInVnbgZ"
      },
      "source": [
        "## 미리 준비된 영어단어 토크나이져 준비 하기\n",
        "* TreebankWordTokenizer 패키지\n",
        " * 영어 표준 토큰화 규격을 따라간다.\n",
        " * Penn Treebank Tokenization 규칙\n",
        "\n",
        "* TreebankWordTokenizer 규칙\n",
        " * 하이푼으로 구성된 단어는 하나의 단어로 유지\n",
        " * doesn't 같이 어포스트로피로 '접어'가 함께하는 단어는 따로 분리\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpT4wQOznmM4"
      },
      "source": [
        "# English Tokenization 실습\n",
        "설치 코드\n",
        "```\n",
        "Colab 및 Jupyter notebook에서 설치\n",
        "!pip install nltk\n",
        "\n",
        "일반 로컬 터미널에서 설치\n",
        "pip install nltk\n",
        "```\n",
        "JVM( Java Virtual Machine )이 설치 되어 있어야 한다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0py1rF9wn-PX",
        "outputId": "e36174c8-a406-40c5-b96d-8711427bfe38"
      },
      "source": [
        "# 영어에 관련된 패키지는 nltk 패키지에 준비가 많이 되어 있음!\n",
        "import nltk\n",
        "nltk.download('punkt') # 영어 토크나이져 패키지 다운로드"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE6rVGBXovgP"
      },
      "source": [
        "sentence = \"Ain't nothin' sweeter, you want this sugar, don't ya?\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lKKi76Do7UM"
      },
      "source": [
        "## [English] 기본 토크나이저"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boTfTfnMpOUr",
        "outputId": "1028266b-3606-4dea-beee-db1d7cd7b434"
      },
      "source": [
        "print(sentence.split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Ain't\", \"nothin'\", 'sweeter,', 'you', 'want', 'this', 'sugar,', \"don't\", 'ya?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl-MbjQzpRpG",
        "outputId": "3b2aebc5-35b9-49e0-8338-4b9a4fdd2ded"
      },
      "source": [
        "# nltk의 기본 Tokenizer 사용\n",
        "from nltk.tokenize import word_tokenize\n",
        "print(word_tokenize(sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJ2ILbyGqSo2"
      },
      "source": [
        "## [English] WordPunctTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7V2-piwqjMF",
        "outputId": "0c33fb30-f691-4ae4-e61a-317255355984"
      },
      "source": [
        "from nltk.tokenize import WordPunctTokenizer\n",
        "tokenizer = WordPunctTokenizer()\n",
        "\n",
        "print(tokenizer.tokenize(sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ain', \"'\", 't', 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'don', \"'\", 't', 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crj7YkEZqvCE"
      },
      "source": [
        "## [English] TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tkgKYDdrX_J",
        "outputId": "3a341484-369d-4aa8-b29f-d0651f4ec29e"
      },
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "tokenizer = TreebankWordTokenizer()\n",
        "print(tokenizer.tokenize(sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Ai', \"n't\", 'nothin', \"'\", 'sweeter', ',', 'you', 'want', 'this', 'sugar', ',', 'do', \"n't\", 'ya', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ohn_l7_IrhBg",
        "outputId": "cf2074be-c483-45c9-d5fd-ef471d530776"
      },
      "source": [
        "print(tokenizer.tokenize(\"I'm Iron-man\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I', \"'m\", 'Iron-man']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OQA6099rugB"
      },
      "source": [
        "# Korean Tokenization 실습\n",
        "설치 코드\n",
        "```\n",
        "Colab 및 Jupyter notebook에서 설치\n",
        "!pip install konlpy\n",
        "\n",
        "일반 로컬 터미널에서 설치\n",
        "pip install konlpy\n",
        "```\n",
        "JVM( Java Virtual Machine )이 설치 되어 있어야 한다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MOgiptBnsOWZ",
        "outputId": "c010f05c-df9c-4006-fd5b-7af215b418da"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 36.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, beautifulsoup4, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ici7s4ysmmY"
      },
      "source": [
        "## Twitter(Okt), 꼬꼬마(Kkma), 코모란(Komoran), 한나눔(Hannanum)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qH3KIDOtE6Q"
      },
      "source": [
        "from konlpy.tag import Hannanum, Kkma, Komoran, Okt\n",
        "\n",
        "hannanum = Hannanum()\n",
        "kkma = Kkma()\n",
        "komoran = Komoran()\n",
        "okt = Okt()\n",
        "\n",
        "sentence = \"좋으니 그 사람 솔직히 견디기 버거워\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF-BlqK6tk7C"
      },
      "source": [
        "# konlpy의 모든 형태소 분리기는 duck typing 기법을 활용하여\n",
        "# 명사 추출, 각 형태소별 토큰화, 형태소 토큰 및 종류를 튜플로 표시하는 기능이 통일\n",
        "def print_tokenizer(tokenizer, s):\n",
        "  print(tokenizer.nouns(s)) # 명사만 추출\n",
        "  print(tokenizer.morphs(s)) # 각 형태소 별로 토큰화\n",
        "  print(tokenizer.pos(s)) # 각 형태소 토큰 및 형태소 종류를 튜플로 표현"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZlh4jAwueF_"
      },
      "source": [
        "### 트위터 ( Okt )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYKUSL1CurHI",
        "outputId": "efcb8e79-8102-48ce-c6d5-440ea33a1f40"
      },
      "source": [
        "print_tokenizer(okt, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['그', '사람']\n",
            "['좋으니', '그', '사람', '솔직히', '견디기', '버거워']\n",
            "[('좋으니', 'Adjective'), ('그', 'Noun'), ('사람', 'Noun'), ('솔직히', 'Adjective'), ('견디기', 'Verb'), ('버거워', 'Adjective')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFcqOyERuteL"
      },
      "source": [
        "### 꼬꼬마(Kkma)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OHIds3Du_mq",
        "outputId": "b5c32706-e25d-418d-d639-1402fbbdad3c"
      },
      "source": [
        "print_tokenizer(kkma, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버겁', '어']\n",
            "[('좋', 'VA'), ('으니', 'ECD'), ('그', 'MDT'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버겁', 'VA'), ('어', 'ECS')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46BL9YxlvBiy"
      },
      "source": [
        "[꼬꼬마 품사 태그표](http://kkma.snu.ac.kr/documents/?doc=postag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QjFuQm0vSiK"
      },
      "source": [
        "### 코모란 ( Komoran )\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGKlx6lDvyyi",
        "outputId": "a92b97ec-7133-48b7-b73a-6201b7ea3e02"
      },
      "source": [
        "print_tokenizer(komoran, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
            "[('좋', 'VA'), ('으니', 'EC'), ('그', 'MM'), ('사람', 'NNG'), ('솔직히', 'MAG'), ('견디', 'VV'), ('기', 'ETN'), ('버거워', 'NA')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gxfMb-nv1Hd"
      },
      "source": [
        "### 한나눔( Hannanum )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57zDDa3UwHnf",
        "outputId": "4dc92588-fbb0-41ea-9bd2-b963751b81a7"
      },
      "source": [
        "print_tokenizer(hannanum, sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['사람', '버거워']\n",
            "['좋', '으니', '그', '사람', '솔직히', '견디', '기', '버거워']\n",
            "[('좋', 'P'), ('으니', 'E'), ('그', 'M'), ('사람', 'N'), ('솔직히', 'M'), ('견디', 'P'), ('기', 'E'), ('버거워', 'N')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olIdtHTSwJvD"
      },
      "source": [
        "# Sentence Tokenization\n",
        "단순히 물음표, 느낌표, 온점(.) 으로만 문장을 잘라내면 문장 토크나이징 일까요??\n",
        "\n",
        "> 니 아이피가 **192.168.56.21** 맞니?\n",
        "\n",
        "> looking for **Ph.D.** Students"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pRNzoAfxBj1"
      },
      "source": [
        "## [English] sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZelmMY9xGor"
      },
      "source": [
        "text = \"Since I'm actively looking for Ph.D. students. I get the same question a dozen times every year.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WtT3GdixNPp",
        "outputId": "337f8525-28b0-4c16-81be-66c5f2bf1b30"
      },
      "source": [
        "# 온점을 이용해서 문장을 나누면...?\n",
        "print(text.split(\".\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Since I'm actively looking for Ph\", 'D', ' students', ' I get the same question a dozen times every year', '']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g60acdD6xTnx",
        "outputId": "3f21ebfe-c3b6-4239-c37c-801557a4ed3f"
      },
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Since I'm actively looking for Ph.D. students.\", 'I get the same question a dozen times every year.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxiSqYNBxapc",
        "outputId": "c1fb8f3c-b00f-45f4-e3b0-45e1227c2f22"
      },
      "source": [
        "text = \"My IP Address is 192.168.56.51. Hello World!\"\n",
        "print(text.split(\".\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['My IP Address is 192', '168', '56', '51', ' Hello World!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCaRVamGxnXH",
        "outputId": "89ce464e-0122-4c5f-ffa0-dd66689b640f"
      },
      "source": [
        "print(sent_tokenize(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['My IP Address is 192.168.56.51.', 'Hello World!']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmbtib6Cxprq"
      },
      "source": [
        "## [Korean] kss\n",
        "\n",
        "설치 방법\n",
        "```\n",
        "!pip install kss\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "godqMC0LCm1j",
        "outputId": "cd46918f-d774-4e4c-c99b-8245b7e1fa2b"
      },
      "source": [
        "!pip install kss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kss\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/ea/3030770642a58a08777dfa324a1b65a2f53f1574de8dd84424851f0c2ec7/kss-2.5.1-py3-none-any.whl (65kB)\n",
            "\r\u001b[K     |█████                           | 10kB 13.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 18.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 30kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 24.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 51kB 25.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 61kB 27.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 7.4MB/s \n",
            "\u001b[?25hInstalling collected packages: kss\n",
            "Successfully installed kss-2.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpJ3uzI3CqRS",
        "outputId": "a3128eeb-1c1a-479c-ec10-82dea9d892f5"
      },
      "source": [
        "import kss\n",
        "text = \"제 아이피는 192.168.56.51 이에요. 자연어 처리가 재미있나요?ㅋㅋ 딥러닝 들어가면 뚝배기가 깨집니다.ㅋㅋ\"\n",
        "\n",
        "print(kss.split_sentences(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['제 아이피는 192.168.56.51 이에요.', '자연어 처리가 재미있나요?ㅋㅋ', '딥러닝 들어가면 뚝배기가 깨집니다.ㅋㅋ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3IhXbyNC544"
      },
      "source": [
        "## [Korean] 띄어쓰기 및 맞춤법 정리\n",
        "\n",
        "### KoSpacing\n",
        "```\n",
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git\n",
        "```\n",
        "### Hanspell\n",
        "```\n",
        "!pip install git+https://github.com/ssut/py-hanspell.git\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0dVb--5DL32"
      },
      "source": [
        "!pip install git+https://github.com/haven-jeon/PyKoSpacing.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QJgkvzgDT-v"
      },
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NL3nj47GDVlC"
      },
      "source": [
        "from pykospacing import Spacing # 한국어 띄어쓰기 관리\n",
        "from hanspell import spell_checker # 한국어 맞춤법 관리"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbWywTxzDmdy"
      },
      "source": [
        "spacing = Spacing() # 띄어쓰기 관리 객체"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRrYaN-FD2pd"
      },
      "source": [
        "text = \"4번놀고있지.4번은팀워크가없어.4번은개인주의야.4번은혼자밖에생각하지않아.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bsBojZOHEAGU",
        "outputId": "662c2527-0857-4275-e80e-01e5e96575af"
      },
      "source": [
        "spacing_text = spacing(text)\n",
        "print(spacing_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4번 놀고 있지.4번은 팀워크가 없어.4번은 개인주의야.4번은 혼자 밖에 생각하지 않아.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-QrVHHgEGDb",
        "outputId": "4191484e-a5af-4bda-c65d-3982b86c191b"
      },
      "source": [
        "hanspell_text = spell_checker.check(text)\n",
        "print(hanspell_text.checked)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4번 놀고 있지. 4번은 팀워크가 없어. 4번은 개인주의야. 4번은 혼자밖에 생각하지 않아.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh0bLV2HEiUj",
        "outputId": "0551b12a-cee4-4f3e-f290-43a42642c3ae"
      },
      "source": [
        "# 맞춤법 검사\n",
        "text = \"맞춤뻡 틀리면 외 않되?\"\n",
        "hanspell_text = spell_checker.check(text).checked\n",
        "print(hanspell_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "맞춤법 틀리면 왜 안돼?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HixTHnUqE2E0"
      },
      "source": [
        "# 텍스트 정규화\n",
        "문장의 복잡도를 낮춰주는 과정. 복잡도가 낮아지기 때문에 **처리할 텍스트가 줄어든다.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXDhPkGpF3Wz"
      },
      "source": [
        "## [English] 정규화 - Stemming 과정\n",
        "어간(stem)을 추출하는 과정 - 영어는 사전에 없는 이상한 단어가 나오는 경우가 있다.\n",
        "* Beautiful : beaut(iful), beaut(y)\n",
        "* Allowance : allow\n",
        "* Medical : medic\n",
        "* Books : book\n",
        "* This : thi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-iz3B6wG63V"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "porter_stemmer = PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05vfWMxJHW2N"
      },
      "source": [
        "text = \"This was not the map we found in Billy Bones's chest, but an accurate copy, complete in all things--names and heights and soundings--with the single exception of the red crosses and the written notes.\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkrUrDkLHsr3",
        "outputId": "eac48c12-5e00-49a5-a896-623b0e0970d8"
      },
      "source": [
        "words = word_tokenize(text)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BgcrCHuTHv_G",
        "outputId": "997a929e-be52-4683-97c3-3f4872fecfe4"
      },
      "source": [
        "stem_list = [porter_stemmer.stem(w) for w in words]\n",
        "print(stem_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSQ6cLDrH9C-"
      },
      "source": [
        "* 언어의 단어 모양이 변경되는 형식은 **자연어 생성 모델**을 만들 때는 사용하면 X\n",
        "* 단순 분류나 회귀문제를 풀 때는 효과가 있을 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2ho2GNPIlgE",
        "outputId": "7cad1971-d45c-463a-9da5-f49dca043481"
      },
      "source": [
        "words = [\"Serialize\", \"Allowance\", \"Allowed\", \"Medical\", \"This\", \"Pretty\", \"Beautiful\"]\n",
        "print([porter_stemmer.stem(w) for w in words])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['serial', 'allow', 'allow', 'medic', 'thi', 'pretti', 'beauti']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBUBwYpyJM8r"
      },
      "source": [
        "## [Korean] 정규화 - Okt 사용( Stemming, Normalization )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2x1HhyvwJi5U",
        "outputId": "bc6b9442-dc70-4a7a-ebcb-a3bd3418e8df"
      },
      "source": [
        "okt= Okt()\n",
        "text = \"이것도 모르고 저것도 모르고 아무것도 모르면 뭘 모르는지도 모르더라.\"\n",
        "\n",
        "print(okt.morphs(text))\n",
        "print(okt.morphs(text, stem=True)) # 어간이 추출된 형태소 분리"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이', '것', '도', '모르고', '저', '것', '도', '모르고', '아무', '것', '도', '모르면', '뭘', '모르는지도', '모르더라', '.']\n",
            "['이', '것', '도', '모르다', '저', '것', '도', '모르다', '아무', '것', '도', '모르다', '뭘', '모르다', '모르다', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsUyEZN9J44F",
        "outputId": "2aba4c8b-119a-4eea-f26a-c02930464c49"
      },
      "source": [
        "print(okt.pos(text))\n",
        "print(okt.pos(text, stem=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('모르고', 'Verb'), ('저', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('모르고', 'Verb'), ('아무', 'Modifier'), ('것', 'Noun'), ('도', 'Josa'), ('모르면', 'Verb'), ('뭘', 'Noun'), ('모르는지도', 'Verb'), ('모르더라', 'Verb'), ('.', 'Punctuation')]\n",
            "[('이', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('모르다', 'Verb'), ('저', 'Determiner'), ('것', 'Noun'), ('도', 'Josa'), ('모르다', 'Verb'), ('아무', 'Modifier'), ('것', 'Noun'), ('도', 'Josa'), ('모르다', 'Verb'), ('뭘', 'Noun'), ('모르다', 'Verb'), ('모르다', 'Verb'), ('.', 'Punctuation')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbcHXcIjKIBu",
        "outputId": "54e35eba-0535-4c95-c913-3bcc9f4bac43"
      },
      "source": [
        "text = \"딥러닝 진짜 어렵닼ㅋㅋㅋㅋㅋ 이렇게 어려울지 몰랐어옄ㅋㅋㅋㅋㅋㅋㅋㅋㅋ\"\n",
        "\n",
        "print(okt.pos(text))\n",
        "print(okt.pos(text, norm=True)) # 정규화"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('딥', 'Noun'), ('러닝', 'Noun'), ('진짜', 'Noun'), ('어렵닼', 'Noun'), ('ㅋㅋㅋㅋㅋ', 'KoreanParticle'), ('이렇게', 'Adverb'), ('어려울지', 'Verb'), ('몰랐어', 'Verb'), ('옄', 'Noun'), ('ㅋㅋㅋㅋㅋㅋㅋㅋㅋ', 'KoreanParticle')]\n",
            "[('딥', 'Noun'), ('러닝', 'Noun'), ('진짜', 'Noun'), ('어렵다', 'Adjective'), ('ㅋㅋㅋ', 'KoreanParticle'), ('이렇게', 'Adverb'), ('어려울지', 'Verb'), ('몰랐어여', 'Verb'), ('ㅋㅋㅋ', 'KoreanParticle')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqwBCppNKg0u",
        "outputId": "f1bc3e2c-48ad-4bd1-cce6-3a9c1e3839bd"
      },
      "source": [
        "# 어간 추출, 정규화를 동시에\n",
        "print(okt.pos(text, stem=True, norm=True))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('딥', 'Noun'), ('러닝', 'Noun'), ('진짜', 'Noun'), ('어렵다', 'Adjective'), ('ㅋㅋㅋ', 'KoreanParticle'), ('이렇게', 'Adverb'), ('어리다', 'Verb'), ('모르다', 'Verb'), ('ㅋㅋㅋ', 'KoreanParticle')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MDvQ3GbK-GA"
      },
      "source": [
        "## [Korean] 이모티콘이나 의미없이 반복되는 문자 정제\n",
        "* ㅋㅋ, ㅋㅋㅋㅋㅋ, ㅋㅋㅋㅋㅋㅋㅋ\n",
        "* ㅎㅎㅎㅎㅎㅎㅎ\n",
        "\n",
        "* 잘한다 ㅠㅠㅠㅠㅠㅠ : 긍정의 표현으로 많이 사용 -> 잘한다 ㅠ\n",
        "* 잘한다 ㅋㅋㅋㅋㅋㅋ : 긍정 또는 약간의 부정으로도 사용될 거 같다. -> 잘한다 ㅋㅋ\n",
        "\n",
        "```\n",
        "!pip install soynlp\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUr8iJPWLcun",
        "outputId": "34ce153c-ffaa-4077-ae92-9d49b06c63ac"
      },
      "source": [
        "!pip install soynlp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting soynlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/50/6913dc52a86a6b189419e59f9eef1b8d599cffb6f44f7bb91854165fc603/soynlp-0.0.493-py3-none-any.whl (416kB)\n",
            "\r\u001b[K     |▉                               | 10kB 15.5MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20kB 19.2MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30kB 22.4MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40kB 25.2MB/s eta 0:00:01\r\u001b[K     |████                            | 51kB 27.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61kB 26.0MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 71kB 23.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 81kB 23.5MB/s eta 0:00:01\r\u001b[K     |███████                         | 92kB 24.2MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 102kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 112kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 122kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 133kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████                     | 143kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 153kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 163kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 174kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 184kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 204kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 215kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 225kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 235kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 245kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 256kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 266kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 276kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 286kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 296kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 307kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 317kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 327kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 337kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 348kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 358kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 368kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 378kB 24.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 389kB 24.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 399kB 24.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 409kB 24.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 419kB 24.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.19.5)\n",
            "Requirement already satisfied: psutil>=5.0.1 in /usr/local/lib/python3.7/dist-packages (from soynlp) (5.4.8)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from soynlp) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->soynlp) (1.0.1)\n",
            "Installing collected packages: soynlp\n",
            "Successfully installed soynlp-0.0.493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1zQAQLYLhbO",
        "outputId": "b8dc30f9-f250-4ca3-f70a-adba15822b10"
      },
      "source": [
        "from soynlp.normalizer import emoticon_normalize\n",
        "\n",
        "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋ 딥러닝 존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ\", num_repeats=2))\n",
        "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 딥러닝 존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ\", num_repeats=2))\n",
        "print(emoticon_normalize(\"앜ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ 딥러닝 존잼쓰ㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠㅠ\", num_repeats=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "아ㅋㅋ 딥러닝 존잼쓰ㅠㅠ\n",
            "아ㅋㅋ 딥러닝 존잼쓰ㅠㅠ\n",
            "아ㅋㅋ 딥러닝 존잼쓰ㅠㅠ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN6JprQHL-tw",
        "outputId": "56c76911-4de2-4b65-98de-77a8cc14c1aa"
      },
      "source": [
        "# 반복되는 문자를 정규화\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "\n",
        "print(repeat_normalize(\"문을 쿵쿵쿵쿵쿵쿵쿵 두드렸다\", num_repeats=2))\n",
        "print(repeat_normalize(\"문을 쿵쿵쿵쿵쿵 두드렸다\", num_repeats=2))\n",
        "print(repeat_normalize(\"문을 쿵쿵쿵쿵 두드렸다\", num_repeats=2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문을 쿵쿵 두드렸다\n",
            "문을 쿵쿵 두드렸다\n",
            "문을 쿵쿵 두드렸다\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYbPpPS0MSCf"
      },
      "source": [
        "# 텍스트 정제 (Cleaning)\n",
        "* 정규식을 이용한 정제\n",
        "  * 특수기호나 의미 없는 공백등을 정규식을 활용하여 제거\n",
        "* 불용어(stopwords) 정제\n",
        "  * 빈도수가 낮거나, 짧거나, 의미 없는 단어를 문장에서 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-WxZzMMQezL",
        "outputId": "f7a6d8c7-d107-4307-98ae-d3355838a813"
      },
      "source": [
        "import re\n",
        "\n",
        "eng_sent = \"\\n\\n\\n\\n\\n\\n\\nYeah, do you expect people to read the FAQ, etc. and actually accept hard\\natheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\\nof steam!\\n\\n\\n\\n\\n\\n\\n\\nJim,\\n\\nSorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\\ndenial about the faith you need to get by.  Oh well, just pretend that it will\\nall end happily ever after anyway.  Maybe if you start a new newsgroup,\\nalt.atheist.hard, you won't be bummin' so much?\\n\\n\\n\\n\\n\\n\\nBye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \\n--\\nBake Timmons, III\"\n",
        "print(eng_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Yeah, do you expect people to read the FAQ, etc. and actually accept hard\n",
            "atheism?  No, you need a little leap of faith, Jimmy.  Your logic runs out\n",
            "of steam!\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jim,\n",
            "\n",
            "Sorry I can't pity you, Jim.  And I'm sorry that you have these feelings of\n",
            "denial about the faith you need to get by.  Oh well, just pretend that it will\n",
            "all end happily ever after anyway.  Maybe if you start a new newsgroup,\n",
            "alt.atheist.hard, you won't be bummin' so much?\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Bye-Bye, Big Jim.  Don't forget your Flintstone's Chewables!  :) \n",
            "--\n",
            "Bake Timmons, III\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwncAy03QkqI",
        "outputId": "5b0db2a7-8229-4593-f0e0-eaf9ed1e72ee"
      },
      "source": [
        "# 위 문장에서 \"영어가 아닌 것\"들을 전부다 공백으로 치환\n",
        "#   sub : replace와 같은 역할\n",
        "eng_sent = re.sub(\"[^a-zA-Z]\", \" \", eng_sent)\n",
        "print(eng_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "       Yeah  do you expect people to read the FAQ  etc  and actually accept hard atheism   No  you need a little leap of faith  Jimmy   Your logic runs out of steam         Jim   Sorry I can t pity you  Jim   And I m sorry that you have these feelings of denial about the faith you need to get by   Oh well  just pretend that it will all end happily ever after anyway   Maybe if you start a new newsgroup  alt atheist hard  you won t be bummin  so much        Bye Bye  Big Jim   Don t forget your Flintstone s Chewables          Bake Timmons  III\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_OMFPUPRZtX",
        "outputId": "74d19831-a5e7-4541-da34-513b2a8bc388"
      },
      "source": [
        "# 4글자 이상인 단어만 추출해서 문장을 새롭게 재구성하기\n",
        "eng_sent = \" \".join([ w for w in eng_sent.split() if len(w) > 3])\n",
        "print(eng_sent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yeah expect people read actually accept hard atheism need little leap faith Jimmy Your logic runs steam Sorry pity sorry that have these feelings denial about faith need well just pretend that will happily ever after anyway Maybe start newsgroup atheist hard bummin much forget your Flintstone Chewables Bake Timmons\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t98UpSPdR1_U"
      },
      "source": [
        "## 한국어 정규 표현식 정제\n",
        "한국어 문장에서 한글만 추출하는 정규식 표현 : `[ㄱ-ㅎㅏ-ㅣ가-힣]`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cr5CDD0HSUOW"
      },
      "source": [
        "kor_sent = \"느그 서장 남천동 살제?? 내가 임마 느그 서장이랑 으이??? hello world\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "E_Ki6Q3nSwxd",
        "outputId": "67c53d3b-f2c3-4872-d1bb-5b48b8588a0c"
      },
      "source": [
        "kor_sent = re.sub(\"[^ㄱ-ㅎㅏ-ㅣ가-힣]\", \" \", kor_sent)\n",
        "kor_sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'느그 서장 남천동 살제   내가 임마 느그 서장이랑 으이               '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yRfkJW1jS8O7",
        "outputId": "15ce2c5f-6270-4287-d851-cbd6b36ba4e8"
      },
      "source": [
        "# 공백이 2개 이상이면 사라지게 하기. 공백 2개 이상을 1개로 치환하기\n",
        "kor_sent = re.sub(\"[ ]{2,}\", \" \", kor_sent)\n",
        "kor_sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'느그 서장 남천동 살제 내가 임마 느그 서장이랑 으이 '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B7N83MD0TvEr",
        "outputId": "8bad3245-d6db-4384-da2e-c8958a996674"
      },
      "source": [
        "kor_sent.strip()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'느그 서장 남천동 살제 내가 임마 느그 서장이랑 으이'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZCwLD9RT01l"
      },
      "source": [
        "# 불용어(stopwords) 정제\n",
        "필요 없는 짧은 단어나 의미가 없는 단어들을 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jju0cCOpUJJo"
      },
      "source": [
        "## [English] 불용어 정제\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxP9-SnLUOxK",
        "outputId": "065ff9ad-5a52-456e-fd8e-2ca6446a3eb7"
      },
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\") # 불용어 사전 다운로드"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WWIulSQUSOq",
        "outputId": "e235f9c8-edcc-4197-a6e3-8bf21464d3fe"
      },
      "source": [
        "# 불용어도 여러분들의 비즈니스에 맞게 설정할 수 있어야 한다.\n",
        "from nltk.corpus import stopwords\n",
        "list(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "atEA3KqxUj4C",
        "outputId": "2dbe2e97-33d2-4228-ba74-ea17c3e897eb"
      },
      "source": [
        "example = \"Family is not an important thing. It's everything\"\n",
        "\n",
        "# 불용어 사전중에 중복된 것이 있을 수도 있기 때문에 중복을 제거\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "word_tokens = word_tokenize(example.lower()) # 문장을 소문자로 만든 다음 토큰화\n",
        "\n",
        "# 불용어 사전에 들어있지 않은 단어면 리스트에 추가\n",
        "result = [w for w in word_tokens if w not in stop_words]\n",
        "\n",
        "print(\"원본 : {}\".format(word_tokens))\n",
        "print(\"불용어 제거 후 : {}\".format(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원본 : ['family', 'is', 'not', 'an', 'important', 'thing', '.', 'it', \"'s\", 'everything']\n",
            "불용어 제거 후 : ['family', 'important', 'thing', '.', \"'s\", 'everything']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RycWQUz7VoCO"
      },
      "source": [
        "## [Korean] 불용어 정제\n",
        "* 한국어 불용어 사전은 직접 만들거나 구글링해서 가져오면 된다.\n",
        "* 개발자가 직접 정의하는 것이 일반적"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTF58QdFV8RT",
        "outputId": "80b62897-7957-4d55-9392-8f06a75eea8f"
      },
      "source": [
        "example = \"내 패와 정마담 패를 밑에서 뺏지. 내가 빙다리 핫바지로 보이냐?\"\n",
        "\n",
        "example_spell_check = spell_checker.check(example).checked\n",
        "\n",
        "word_tokens = okt.morphs(example_spell_check)\n",
        "\n",
        "print(word_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['내', '패', '와', '정마담', '패', '를', '밑', '에서', '뺏지', '.', '내', '가', '비', '에', '다리', '핫바', '지로', '보이냐', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOsJR8E6WQHv"
      },
      "source": [
        "# 개발자가 임의로 불용어를 선정할 수 있다.\n",
        "# 일반적으로 조사, 접속사들이 불용어로 선정된다.\n",
        "stop_words = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다', '것', '게', '에서']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFAEqpqFW-Ry",
        "outputId": "f3b50aac-28a8-40d0-a808-9a67c659cb7d"
      },
      "source": [
        "result = [w for w in word_tokens if not w in stop_words]\n",
        "\n",
        "print(\"원문 : \",word_tokens)\n",
        "print(\"불용어 제거 후 : {}\".format(result))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원문 :  ['내', '패', '와', '정마담', '패', '를', '밑', '에서', '뺏지', '.', '내', '가', '비', '에', '다리', '핫바', '지로', '보이냐', '?']\n",
            "불용어 제거 후 : ['내', '패', '정마담', '패', '밑', '뺏지', '.', '내', '비', '다리', '핫바', '지로', '보이냐', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}