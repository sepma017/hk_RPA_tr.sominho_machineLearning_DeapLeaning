{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02. 텍스트 분석을 위한 인코딩",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fqs2oB2Hif3"
      },
      "source": [
        "# 텍스트의 수치화\n",
        "컴퓨터는 텍스트보다 숫자를 더 잘 처리한다. 텍스트를 수치화 시키는 작업에 대해 알아봄\n",
        "1. Integer Encoding ( 정수 인코딩 )\n",
        "  * 단어 토큰화( Word Tokenization ) 또는 형태소 분리 후에 각 단어에 대한 **고유한 정수**를 부여\n",
        "  * 중복이 허용되지 않는 모든 단어들의 집합을 만들어야 한다. **단어 집합(Vocabulary)**이라고 한다.\n",
        "2. Padding\n",
        "  * 모든 문장에 대해서 정수 인코딩을 했을 때 문장마다의 길이가 다를 수 있다.\n",
        "  * 이때 가상의 단어( 예를 들면 `<pad>` )를 만들어서 단어집합에 0번으로 추가시켜 준다. 이를 Padding 작업이라고 한다.\n",
        "  * 짧은 길이의 문장의 제일 앞이나 뒤에 `<pad>` 정수를 추가\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWgiDsrQIRB_"
      },
      "source": [
        "## Integer Encoding\n",
        "토큰에 고유한 정수를 부여하는 작업\n",
        "\n",
        "숫자를 부여하는 기준은 ABC(가나다)순 또는 빈도가 높은 순으로 순서를 구성\n",
        "* 많이 등장한 단어일수록 작은 정수를 부여받는 식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxQIay4uJCzD",
        "outputId": "8670dc52-37ee-4fd3-b561-3448e7c4cdb8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGnXJmsGJL7L"
      },
      "source": [
        "## [English] Sesntence Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onNwNK5HJUJA"
      },
      "source": [
        "text = \"\"\"Isn't she lovely.\n",
        "Isn't she wonderful.\n",
        "Isn't she precious.\n",
        "Less than one minute old.\n",
        "I never thought through love we'd be.\n",
        "Making one as lovely as she.\n",
        "But isn't she lovely made from love.\n",
        "Isn't she pretty.\n",
        "Truly the angel's best.\n",
        "Boy, I'm so happy.\n",
        "We have been heaven blessed.\n",
        "I can't believe what God has done.\n",
        "Through us he's given life to one.\n",
        "But isn't she lovely made from love.\n",
        "Isn't she lovely.\n",
        "Life and love are the same.\n",
        "Life is Aisha.\n",
        "The meaning of her name.\n",
        "Londie, it could have not been done.\n",
        "Without you who conceived the one.\n",
        "That's so very lovely made from love.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mnMtzqOJeSB",
        "outputId": "59400594-9e97-40e0-ed4c-2f7a23587607"
      },
      "source": [
        "# Sentence Tokenization\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokens = sent_tokenize(text)\n",
        "print(sent_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"Isn't she lovely.\", \"Isn't she wonderful.\", \"Isn't she precious.\", 'Less than one minute old.', \"I never thought through love we'd be.\", 'Making one as lovely as she.', \"But isn't she lovely made from love.\", \"Isn't she pretty.\", \"Truly the angel's best.\", \"Boy, I'm so happy.\", 'We have been heaven blessed.', \"I can't believe what God has done.\", \"Through us he's given life to one.\", \"But isn't she lovely made from love.\", \"Isn't she lovely.\", 'Life and love are the same.', 'Life is Aisha.', 'The meaning of her name.', 'Londie, it could have not been done.', 'Without you who conceived the one.', \"That's so very lovely made from love.\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fsn6NmoJqLK"
      },
      "source": [
        "## [English] Word Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujbbhiyHJ5n8",
        "outputId": "3d3fee7e-6cef-4364-da40-4f922b864145"
      },
      "source": [
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5erw6_yJ8PI"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english')) # 불용어 집합화"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjmObYBkKSU3",
        "outputId": "97aae950-dc42-4bc1-a2e3-9095703d4f61"
      },
      "source": [
        "# 단어 토큰화된 전체 문장을 가지고 있을 리스트\n",
        "sentences = []\n",
        "\n",
        "# 문장을 하나씩 꺼내서 단어 토큰화\n",
        "for sent in sent_tokens:\n",
        "  word_tokens = word_tokenize(sent) # 각 문장에 대한 단어 토큰화\n",
        "  result = [] # 정제 작업이 완료된 단어를 추가할 배열 ( 불용어 처리, 길이가 짧은 단어를 제외 처리 )\n",
        "\n",
        "  for word in word_tokens:\n",
        "    # 소문자화\n",
        "    word = word.lower() # 모든 단어를 소문자화 하여 정규화( Normalization )\n",
        "\n",
        "    # 불용어 처리\n",
        "    if word not in stop_words:\n",
        "      # 단어의 길이가 2 초과인 것만 사용하기\n",
        "      if len(word) > 2:\n",
        "        result.append(word)\n",
        "        \n",
        "  \n",
        "  sentences.append(result)\n",
        "\n",
        "print(sentences)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[\"n't\", 'lovely'], [\"n't\", 'wonderful'], [\"n't\", 'precious'], ['less', 'one', 'minute', 'old'], ['never', 'thought', 'love'], ['making', 'one', 'lovely'], [\"n't\", 'lovely', 'made', 'love'], [\"n't\", 'pretty'], ['truly', 'angel', 'best'], ['boy', 'happy'], ['heaven', 'blessed'], [\"n't\", 'believe', 'god', 'done'], ['given', 'life', 'one'], [\"n't\", 'lovely', 'made', 'love'], [\"n't\", 'lovely'], ['life', 'love'], ['life', 'aisha'], ['meaning', 'name'], ['londie', 'could', 'done'], ['without', 'conceived', 'one'], ['lovely', 'made', 'love']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7k0ISmyLHbH"
      },
      "source": [
        "## [English] 단어 집합 만들기 (Python)\n",
        "규칙 : 등장한 횟수가 많은 단어 일수록 앞 번호에 위치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQCfyoMMNfCV",
        "outputId": "23407ea3-1c4c-4e92-c83c-60ffa0e2e345"
      },
      "source": [
        "# 1. 문장 별로 모여있는 단어들을 하나도 풀어서 합치기\n",
        "words = sum(sentences, []) # sentences에 들어있는 모든 배열을 비어있는 배열에 합치는 역할( extends )\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"n't\", 'lovely', \"n't\", 'wonderful', \"n't\", 'precious', 'less', 'one', 'minute', 'old', 'never', 'thought', 'love', 'making', 'one', 'lovely', \"n't\", 'lovely', 'made', 'love', \"n't\", 'pretty', 'truly', 'angel', 'best', 'boy', 'happy', 'heaven', 'blessed', \"n't\", 'believe', 'god', 'done', 'given', 'life', 'one', \"n't\", 'lovely', 'made', 'love', \"n't\", 'lovely', 'life', 'love', 'life', 'aisha', 'meaning', 'name', 'londie', 'could', 'done', 'without', 'conceived', 'one', 'lovely', 'made', 'love']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJZWImKsOADp",
        "outputId": "e53df1c0-c51b-41d7-f7b1-6333f71cc950"
      },
      "source": [
        "# 2. 빈도수 구하기\n",
        "from collections import Counter # 횟수 세기 용도\n",
        "vocab = Counter(words) # 배열 내 단어들의 모든 빈도를 손쉽게 계산 가능\n",
        "print(vocab)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({\"n't\": 8, 'lovely': 6, 'love': 5, 'one': 4, 'made': 3, 'life': 3, 'done': 2, 'wonderful': 1, 'precious': 1, 'less': 1, 'minute': 1, 'old': 1, 'never': 1, 'thought': 1, 'making': 1, 'pretty': 1, 'truly': 1, 'angel': 1, 'best': 1, 'boy': 1, 'happy': 1, 'heaven': 1, 'blessed': 1, 'believe': 1, 'god': 1, 'given': 1, 'aisha': 1, 'meaning': 1, 'name': 1, 'londie': 1, 'could': 1, 'without': 1, 'conceived': 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRy88raUOjR6",
        "outputId": "cd9dd7af-5a2f-4a5c-9bfa-38b8801a101a"
      },
      "source": [
        "# lovely는 몇번 나왔나?\n",
        "vocab['lovely']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5l6mFB54O1Cj"
      },
      "source": [
        "가나다 순 또는 **빈도 내림차순**으로 정렬하여 각 단어에 중복되지 않는 정수를 부여"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvjLD9XJPNWj",
        "outputId": "8720fe34-4b63-4893-c8df-f02108081801"
      },
      "source": [
        "# 빈도수가 높은 순서대로 정렬해서 리스트에 넣어 놓기\n",
        "# dict의 items를 뽑아서 value로 내림차순 정렬....\n",
        "vocab_sorted = sorted(vocab.items(), key=lambda x : x[1], reverse=True)\n",
        "print(vocab_sorted)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(\"n't\", 8), ('lovely', 6), ('love', 5), ('one', 4), ('made', 3), ('life', 3), ('done', 2), ('wonderful', 1), ('precious', 1), ('less', 1), ('minute', 1), ('old', 1), ('never', 1), ('thought', 1), ('making', 1), ('pretty', 1), ('truly', 1), ('angel', 1), ('best', 1), ('boy', 1), ('happy', 1), ('heaven', 1), ('blessed', 1), ('believe', 1), ('god', 1), ('given', 1), ('aisha', 1), ('meaning', 1), ('name', 1), ('londie', 1), ('could', 1), ('without', 1), ('conceived', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmZxyeWiQZrY"
      },
      "source": [
        "높은 빈도수를 가진 단어 일수록 낮은 정수 인덱스를 부여( 앞쪽에 배치 )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNHhEcveQnOf",
        "outputId": "a998216c-0027-468b-b5b3-463558cf7ebf"
      },
      "source": [
        "word2idx = {}\n",
        "i = 0\n",
        "\n",
        "for (word, frequency) in vocab_sorted:\n",
        "  \n",
        "  # 정제 작업. 빈도수가 적은 단어는 제외\n",
        "  if frequency > 1:\n",
        "    i = i+1\n",
        "    word2idx[word] = i # 딕셔너리에 단어와 정수를 추가\n",
        "\n",
        "print(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"n't\": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, 'life': 6, 'done': 7}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1pHyVPfQ-eM"
      },
      "source": [
        "빈도수가 가장 높은 **상위 n**개만 선택해서 단어집합으로 사용하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiobCQhzRRg_",
        "outputId": "ccf4ca00-f3e2-49ef-8690-c4f63d2c0f48"
      },
      "source": [
        "vocab_size = 5 # 단어 집합의 크기... 반드시 외워두세요!\n",
        "\n",
        "# 포함 되지 않을 단어 구하기\n",
        "del_word = [ w for w, idx in word2idx.items() if idx >= vocab_size + 1]\n",
        "print(del_word)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['life', 'done']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bXbw3mfR_SU",
        "outputId": "880e4236-f584-453a-ca58-f4f45f1d2a42"
      },
      "source": [
        "for w in del_word:\n",
        "  del word2idx[w]\n",
        "  \n",
        "print(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"n't\": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEOBBmmgV49w"
      },
      "source": [
        "## Encoding 수행하기\n",
        "* 단어를 숫자로 표현하는 것을 인코딩이라고 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn5trE15XRUI",
        "outputId": "8459455e-1d8b-43df-97d1-eaa5b9aa9752"
      },
      "source": [
        "# UNK 토큰 만들기\n",
        "word2idx[\"<oov>\"] = 6\n",
        "print(word2idx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"n't\": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, '<oov>': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxBZheYLXYZT",
        "outputId": "cbff59da-e625-411e-dc86-d61c6355a707"
      },
      "source": [
        "# 인코딩된 데이터를 저장하기 위한 배열\n",
        "encoded = []\n",
        "\n",
        "for sent in sentences:\n",
        "  # 임시로 인코딩된 내용을 저장\n",
        "  temp = []\n",
        "\n",
        "  # 단어를 하나씩 꺼내기\n",
        "  for w in sent:\n",
        "    if w in word2idx: # 단어집합에 단어가 있으면\n",
        "      temp.append(word2idx[w]) # 키값에 맞는 정수를 추가\n",
        "    else : # 키값이 없으면\n",
        "      temp.append(word2idx[\"<oov>\"]) # 단어 집합에 없는 단어는 <oov>토큰의 정수 추가\n",
        "  \n",
        "  encoded.append(temp)\n",
        "\n",
        "print(\"변환 전 : {}\".format(sentences[:5]))\n",
        "print(\"변환 후 : {}\".format(encoded[:5]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "변환 전 : [[\"n't\", 'lovely'], [\"n't\", 'wonderful'], [\"n't\", 'precious'], ['less', 'one', 'minute', 'old'], ['never', 'thought', 'love']]\n",
            "변환 후 : [[1, 2], [1, 6], [1, 6], [6, 4, 6, 6], [6, 6, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9kI1SDcXyHf"
      },
      "source": [
        "## [English] Vocab & Integer Encoding (Tensorflow)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc5gXgl_Y1Kq"
      },
      "source": [
        "# Tensorflow의 Tokenizer 불러오기\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYIC1E6iY_TH",
        "outputId": "ca64d4cf-128b-45c5-cfff-2e1e5f60a677"
      },
      "source": [
        "# fit_on_texts() 함수에 코퍼스(sentences)를 집어 넣으면 바로 빈도수를 기준으로 단어 집합을 만들어 준다.\n",
        "tokenizer.fit_on_texts(sentences) # 형태소 분리의 결과가 들어간다. 이 때 형태소 분리의 결과는 반드시 항상 2차원 리스트여야만 한다.\n",
        "\n",
        "print(tokenizer.word_index) # 생성된 단어 집합은 word_index로 가져올 수 있다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"n't\": 1, 'lovely': 2, 'love': 3, 'one': 4, 'made': 5, 'life': 6, 'done': 7, 'wonderful': 8, 'precious': 9, 'less': 10, 'minute': 11, 'old': 12, 'never': 13, 'thought': 14, 'making': 15, 'pretty': 16, 'truly': 17, 'angel': 18, 'best': 19, 'boy': 20, 'happy': 21, 'heaven': 22, 'blessed': 23, 'believe': 24, 'god': 25, 'given': 26, 'aisha': 27, 'meaning': 28, 'name': 29, 'londie': 30, 'could': 31, 'without': 32, 'conceived': 33}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdY-Aev1ZhpV",
        "outputId": "f7d8070c-378b-419f-dff0-53adaac10b01"
      },
      "source": [
        "# 단어의 빈도수 확인하기\n",
        "print(tokenizer.word_counts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([(\"n't\", 8), ('lovely', 6), ('wonderful', 1), ('precious', 1), ('less', 1), ('one', 4), ('minute', 1), ('old', 1), ('never', 1), ('thought', 1), ('love', 5), ('making', 1), ('made', 3), ('pretty', 1), ('truly', 1), ('angel', 1), ('best', 1), ('boy', 1), ('happy', 1), ('heaven', 1), ('blessed', 1), ('believe', 1), ('god', 1), ('done', 2), ('given', 1), ('life', 3), ('aisha', 1), ('meaning', 1), ('name', 1), ('londie', 1), ('could', 1), ('without', 1), ('conceived', 1)])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZPY_M2iZvwz",
        "outputId": "3d5ad96d-4225-4ab2-f52d-10681e097f53"
      },
      "source": [
        "# 인코딩(texts_to_sequences)\n",
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1, 2], [1, 8], [1, 9], [10, 4, 11, 12], [13, 14, 3], [15, 4, 2], [1, 2, 5, 3], [1, 16], [17, 18, 19], [20, 21], [22, 23], [1, 24, 25, 7], [26, 6, 4], [1, 2, 5, 3], [1, 2], [6, 3], [6, 27], [28, 29], [30, 31, 7], [32, 33, 4], [2, 5, 3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C5gVlxqaDbS",
        "outputId": "187614d8-e948-49a7-f66f-b48a560edb3e"
      },
      "source": [
        "# 디코딩(sequences_to_texts)\n",
        "print(tokenizer.sequences_to_texts([[1, 2], [1, 9]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\"n't lovely\", \"n't precious\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP10u1AeaUIi"
      },
      "source": [
        "## OOV 및 Padding 설정\n",
        "keras의 Tokenizer에서는 `pad : 0`, `oov : 1`로 자동 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iocGGWKCatiL",
        "outputId": "3d94e519-db0b-477f-d979-c1136df4c612"
      },
      "source": [
        "# 상위 5개의 토큰만 사용하기\n",
        "vocab_size = 5\n",
        "\n",
        "# num_words : 단어집합 내애서 사용할 단어 개수\n",
        "tokenizer = Tokenizer(num_words=vocab_size+2, oov_token=\"<oov>\" ) # 기본 단어 집합에 padding, oov 토큰을 추가적으로 부여해야 하기 때문에 +2 했음\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "print(tokenizer.texts_to_sequences(sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2, 3], [2, 1], [2, 1], [1, 5, 1, 1], [1, 1, 4], [1, 5, 3], [2, 3, 6, 4], [2, 1], [1, 1, 1], [1, 1], [1, 1], [2, 1, 1, 1], [1, 1, 5], [2, 3, 6, 4], [2, 3], [1, 4], [1, 1], [1, 1], [1, 1, 1], [1, 1, 5], [3, 6, 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cr2bG71Jbn4r",
        "outputId": "d6359a94-d3e8-4f06-8810-d04fd9c0fa3f"
      },
      "source": [
        "print(\"OOV 토큰의 인덱스 : {}\".format(tokenizer.word_index[\"<oov>\"]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OOV 토큰의 인덱스 : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "147LCJcrbx0T"
      },
      "source": [
        "# [Korean] 토큰화 및 정수 인코딩을 Tensorflow로 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KYjMRQ1ce3v",
        "outputId": "70d577f9-4e6d-44ca-c6fa-5f78952b5447"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 2.0MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 35.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Installing collected packages: colorama, beautifulsoup4, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vchwRYqRcnf-"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import urllib.request\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8uAyd8Gc5-d",
        "outputId": "e343c8d3-bfaf-4904-aef6-78b9f7c290ef"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_test.txt', <http.client.HTTPMessage at 0x7f85b00c4910>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sKEivXOOc-cR",
        "outputId": "c05de087-cdc3-404d-ac23-900094aab0c4"
      },
      "source": [
        "df_train = pd.read_table(\"ratings_test.txt\", encoding='utf-8')\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td>GDNTOPCLASSINTHECLUB</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                           document  label\n",
              "0  6270596                                                굳 ㅋ      1\n",
              "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
              "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
              "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXXYHKXzdMPr",
        "outputId": "fe61bd1f-1303-4b9b-f12f-50b8d50bb52f"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 50000 entries, 0 to 49999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        50000 non-null  int64 \n",
            " 1   document  49997 non-null  object\n",
            " 2   label     50000 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApNELr9KdQnv"
      },
      "source": [
        "1. null 값 제거\n",
        "2. 중복 문장 제거\n",
        "3. 특수 문자 및 영어 제거"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSYtu9MIdaVx"
      },
      "source": [
        "각 문장별 형태소 분리 후 Tokenizer에 집어 넣어서 단어 집합 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvMYZ8DEdkAY",
        "outputId": "c56637c1-9162-4b61-a4f3-868be4a5c5af"
      },
      "source": [
        "# 중복 데이터 제거, nan값 제거\n",
        "df_train = df_train.drop_duplicates(subset=['document'])\n",
        "df_train = df_train.dropna(how='any')\n",
        "\n",
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 49157 entries, 0 to 49999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        49157 non-null  int64 \n",
            " 1   document  49157 non-null  object\n",
            " 2   label     49157 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1dCtSntWmfoU",
        "outputId": "e5f9b194-ef49-436b-e02d-22933aeaf94a"
      },
      "source": [
        "# 정규식 이용해서 한글 데이터만 추출\n",
        "df_train['document'] = df_train['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", '')\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9274899</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                   document  label\n",
              "0  6270596                                        굳 ㅋ      1\n",
              "1  9274899                                                 0\n",
              "2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
              "4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "lThdjrfAnJf5",
        "outputId": "690cbcbf-7ede-4738-cdda-94df11fa18f8"
      },
      "source": [
        "df_train['document'].replace('', np.nan, inplace=True)\n",
        "df_train = df_train.dropna(how='any')\n",
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6270596</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8544678</td>\n",
              "      <td>뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6825595</td>\n",
              "      <td>지루하지는 않은데 완전 막장임 돈주고 보기에는</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6723715</td>\n",
              "      <td>만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>7898805</td>\n",
              "      <td>음악이 주가 된 최고의 음악영화</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id                                   document  label\n",
              "0  6270596                                        굳 ㅋ      1\n",
              "2  8544678           뭐야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아      0\n",
              "3  6825595                  지루하지는 않은데 완전 막장임 돈주고 보기에는      0\n",
              "4  6723715  만 아니었어도 별 다섯 개 줬을텐데 왜 로 나와서 제 심기를 불편하게 하죠      0\n",
              "5  7898805                          음악이 주가 된 최고의 음악영화      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouKcVDYungnD",
        "outputId": "d765790a-f02f-462a-bbcc-62ba8047b327"
      },
      "source": [
        "df_train['document'].nunique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48417"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-6lFc4FnmA1",
        "outputId": "e33e1985-423a-4b95-adb9-f7a7ce7093fd"
      },
      "source": [
        "df_train.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id          0\n",
              "document    0\n",
              "label       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLzdSrRynpwn",
        "outputId": "29d17e25-f80d-4e6d-ef9f-51e391f906df"
      },
      "source": [
        "df_train.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 48995 entries, 0 to 49999\n",
            "Data columns (total 3 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        48995 non-null  int64 \n",
            " 1   document  48995 non-null  object\n",
            " 2   label     48995 non-null  int64 \n",
            "dtypes: int64(2), object(1)\n",
            "memory usage: 1.5+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXU5Qx4RnsP5"
      },
      "source": [
        "불용어 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6VsjExooG3Z"
      },
      "source": [
        "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wza06EqMoHbK"
      },
      "source": [
        "일반적으로 한국어에 대한 불용어 처리는 stemming, normalization 적용 후에 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERQa_gZhoOCz"
      },
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Fho_RjhoSTE",
        "outputId": "f6ab6cc8-3a2b-4e09-ff54-d144d6ec7072"
      },
      "source": [
        "X_train = []\n",
        "\n",
        "for sentence in df_train['document']:\n",
        "  temp_X = []\n",
        "  temp_X = okt.morphs(sentence, stem=True, norm=True)\n",
        "  temp_X = [word for word in temp_X if not word in stopwords] # 불옹어 제거\n",
        "\n",
        "  X_train.append(temp_X)\n",
        "\n",
        "X_train[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['굳다', 'ㅋ'],\n",
              " ['뭐', '야', '평점', '나쁘다', '않다', '점', '짜다', '리', '더', '더욱', '아니다'],\n",
              " ['지루하다', '않다', '완전', '막장', '임', '돈', '주다', '보기', '에는']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvaxErcuok_5"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwd57JE_qRwk",
        "outputId": "6889eb2f-8647-40f8-f163-3e1609085d6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenizer.texts_to_sequences(X_train)[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[619, 92],\n",
              " [62, 168, 24, 389, 20, 21, 278, 760, 43, 854, 18],\n",
              " [67, 20, 91, 373, 110, 111, 60, 148, 245]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19BX05oTqTxe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}